{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:20:46.309985Z",
     "iopub.status.busy": "2025-10-02T14:20:46.309657Z",
     "iopub.status.idle": "2025-10-02T14:20:50.628629Z",
     "shell.execute_reply": "2025-10-02T14:20:50.627975Z"
     "shell.execute_reply.started": "2025-10-02T14:20:46.309914Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:20:50.629958Z",
     "iopub.status.busy": "2025-10-02T14:20:50.629738Z",
     "iopub.status.idle": "2025-10-02T14:20:50.633304Z",
     "shell.execute_reply": "2025-10-02T14:20:50.632450Z",
     "shell.execute_reply.started": "2025-10-02T14:20:50.629937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # data_dir = '../input/optiver-realized-volatility-prediction/'\n",
    "    data_dir = 'F:/SF2935/project/'\n",
    "    seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:20:50.634820Z",
     "iopub.status.busy": "2025-10-02T14:20:50.634602Z",
     "iopub.status.idle": "2025-10-02T14:20:50.854037Z",
     "shell.execute_reply": "2025-10-02T14:20:50.853123Z",
     "shell.execute_reply.started": "2025-10-02T14:20:50.634799Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "stock_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "target",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "df141b48-73e5-479b-a8eb-e5c004272db8",
       "rows": [
        [
         "0",
         "0",
         "5",
         "0.004135767"
        ],
        [
         "1",
         "0",
         "11",
         "0.001444587"
        ],
        [
         "2",
         "0",
         "16",
         "0.002168189"
        ],
        [
         "3",
         "0",
         "31",
         "0.002195261"
        ],
        [
         "4",
         "0",
         "62",
         "0.001747216"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  time_id    target\n",
       "0         0        5  0.004136\n",
       "1         0       11  0.001445\n",
       "2         0       16  0.002168\n",
       "3         0       31  0.002195\n",
       "4         0       62  0.001747"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(Config.data_dir + 'train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:20:50.855739Z",
     "iopub.status.busy": "2025-10-02T14:20:50.855489Z",
     "iopub.status.idle": "2025-10-02T14:20:50.866148Z",
     "shell.execute_reply": "2025-10-02T14:20:50.865326Z",
     "shell.execute_reply.started": "2025-10-02T14:20:50.855717Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  26,  27,  28,\n",
       "        29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "        42,  43,  44,  46,  47,  48,  50,  51,  52,  53,  55,  56,  58,\n",
       "        59,  60,  61,  62,  63,  64,  66,  67,  68,  69,  70,  72,  73,\n",
       "        74,  75,  76,  77,  78,  80,  81,  82,  83,  84,  85,  86,  87,\n",
       "        88,  89,  90,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
       "       103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       118, 119, 120, 122, 123, 124, 125, 126], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.stock_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:20:50.867649Z",
     "iopub.status.busy": "2025-10-02T14:20:50.867307Z",
     "iopub.status.idle": "2025-10-02T14:20:50.886125Z",
     "shell.execute_reply": "2025-10-02T14:20:50.885334Z",
     "shell.execute_reply.started": "2025-10-02T14:20:50.867607Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "stock_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "row_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "ddf3ee2c-48e6-4021-b5c6-2e30defcb2b9",
       "rows": [
        [
         "0",
         "0",
         "4",
         "0-4"
        ],
        [
         "1",
         "0",
         "32",
         "0-32"
        ],
        [
         "2",
         "0",
         "34",
         "0-34"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0-32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0-34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  time_id row_id\n",
       "0         0        4    0-4\n",
       "1         0       32   0-32\n",
       "2         0       34   0-34"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(Config.data_dir + 'test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:20:50.887621Z",
     "iopub.status.busy": "2025-10-02T14:20:50.887300Z",
     "iopub.status.idle": "2025-10-02T14:20:50.920830Z",
     "shell.execute_reply": "2025-10-02T14:20:50.919948Z",
     "shell.execute_reply.started": "2025-10-02T14:20:50.887588Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "stock_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "3606f0d4-3420-4bd7-a541-319349ca7db5",
       "rows": [
        [
         "0",
         "3830"
        ],
        [
         "1",
         "3830"
        ],
        [
         "2",
         "3830"
        ],
        [
         "3",
         "3830"
        ],
        [
         "4",
         "3830"
        ],
        [
         "5",
         "3830"
        ],
        [
         "6",
         "3830"
        ],
        [
         "7",
         "3830"
        ],
        [
         "8",
         "3830"
        ],
        [
         "9",
         "3830"
        ],
        [
         "10",
         "3830"
        ],
        [
         "11",
         "3830"
        ],
        [
         "13",
         "3829"
        ],
        [
         "14",
         "3830"
        ],
        [
         "15",
         "3830"
        ],
        [
         "16",
         "3830"
        ],
        [
         "17",
         "3830"
        ],
        [
         "18",
         "3830"
        ],
        [
         "19",
         "3830"
        ],
        [
         "20",
         "3830"
        ],
        [
         "21",
         "3830"
        ],
        [
         "22",
         "3830"
        ],
        [
         "23",
         "3830"
        ],
        [
         "26",
         "3830"
        ],
        [
         "27",
         "3830"
        ],
        [
         "28",
         "3830"
        ],
        [
         "29",
         "3830"
        ],
        [
         "30",
         "3830"
        ],
        [
         "31",
         "3830"
        ],
        [
         "32",
         "3830"
        ],
        [
         "33",
         "3830"
        ],
        [
         "34",
         "3830"
        ],
        [
         "35",
         "3830"
        ],
        [
         "36",
         "3830"
        ],
        [
         "37",
         "3830"
        ],
        [
         "38",
         "3815"
        ],
        [
         "39",
         "3830"
        ],
        [
         "40",
         "3830"
        ],
        [
         "41",
         "3830"
        ],
        [
         "42",
         "3830"
        ],
        [
         "43",
         "3830"
        ],
        [
         "44",
         "3830"
        ],
        [
         "46",
         "3830"
        ],
        [
         "47",
         "3830"
        ],
        [
         "48",
         "3830"
        ],
        [
         "50",
         "3830"
        ],
        [
         "51",
         "3830"
        ],
        [
         "52",
         "3830"
        ],
        [
         "53",
         "3830"
        ],
        [
         "55",
         "3830"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 112
       }
      },
      "text/plain": [
       "stock_id\n",
       "0      3830\n",
       "1      3830\n",
       "2      3830\n",
       "3      3830\n",
       "4      3830\n",
       "       ... \n",
       "122    3830\n",
       "123    3830\n",
       "124    3830\n",
       "125    3830\n",
       "126    3830\n",
       "Length: 112, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique size values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3830, 3829, 3815, 3820], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.groupby('stock_id').size())\n",
    "\n",
    "print(\"\\nUnique size values\")\n",
    "display(train.groupby('stock_id').size().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:20:50.922160Z",
     "iopub.status.busy": "2025-10-02T14:20:50.921893Z",
     "iopub.status.idle": "2025-10-02T14:20:50.927184Z",
     "shell.execute_reply": "2025-10-02T14:20:50.926316Z",
     "shell.execute_reply.started": "2025-10-02T14:20:50.922134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_trade_and_book_by_stock_and_time_id(stock_id, time_id=None, dataType = 'train'):\n",
    "    book_example = pd.read_parquet(f'{Config.data_dir}book_{dataType}.parquet/stock_id={stock_id}')\n",
    "    trade_example =  pd.read_parquet(f'{Config.data_dir}trade_{dataType}.parquet/stock_id={stock_id}')\n",
    "    if time_id:\n",
    "        book_example = book_example[book_example['time_id']==time_id]\n",
    "        trade_example = trade_example[trade_example['time_id']==time_id]\n",
    "    book_example.loc[:,'stock_id'] = stock_id\n",
    "    trade_example.loc[:,'stock_id'] = stock_id\n",
    "    return book_example, trade_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:20:50.930776Z",
     "iopub.status.busy": "2025-10-02T14:20:50.930372Z",
     "iopub.status.idle": "2025-10-02T14:20:50.944143Z",
     "shell.execute_reply": "2025-10-02T14:20:50.943282Z",
     "shell.execute_reply.started": "2025-10-02T14:20:50.930738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff() \n",
    "\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "def calculate_wap1(df):\n",
    "    a1 = df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']\n",
    "    b1 = df['bid_size1'] + df['ask_size1']\n",
    "    a2 = df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']\n",
    "    b2 = df['bid_size2'] + df['ask_size2']\n",
    "    \n",
    "    x = (a1/b1 + a2/b2)/ 2\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def calculate_wap2(df):\n",
    "        \n",
    "    a1 = df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']\n",
    "    a2 = df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']\n",
    "    b = df['bid_size1'] + df['ask_size1'] + df['bid_size2']+ df['ask_size2']\n",
    "    \n",
    "    x = (a1 + a2)/ b\n",
    "    return x\n",
    "\n",
    "def realized_volatility_per_time_id(file_path, prediction_column_name):\n",
    "\n",
    "    stock_id = file_path.split('=')[1]\n",
    "\n",
    "    df_book = pd.read_parquet(file_path)\n",
    "    df_book['wap1'] = calculate_wap1(df_book)\n",
    "    df_book['wap2'] = calculate_wap2(df_book)\n",
    "\n",
    "    df_book['log_return1'] = df_book.groupby(['time_id'])['wap1'].apply(log_return)\n",
    "    df_book['log_return2'] = df_book.groupby(['time_id'])['wap2'].apply(log_return)\n",
    "    df_book = df_book[~df_book['log_return1'].isnull()]\n",
    "\n",
    "    df_rvps =  pd.DataFrame(df_book.groupby(['time_id'])[['log_return1', 'log_return2']].agg(realized_volatility)).reset_index()\n",
    "    df_rvps[prediction_column_name] = 0.6 * df_rvps['log_return1'] + 0.4 * df_rvps['log_return2']\n",
    "\n",
    "    df_rvps['row_id'] = df_rvps['time_id'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    \n",
    "    return df_rvps[['row_id',prediction_column_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:20:50.946193Z",
     "iopub.status.busy": "2025-10-02T14:20:50.945917Z",
     "iopub.status.idle": "2025-10-02T14:20:50.960525Z",
     "shell.execute_reply": "2025-10-02T14:20:50.959685Z",
     "shell.execute_reply.started": "2025-10-02T14:20:50.946169Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_agg_info(df):\n",
    "    agg_df = df.groupby(['stock_id', 'time_id']).agg(mean_sec_in_bucket = ('seconds_in_bucket', 'mean'), \n",
    "                                                     mean_price = ('price', 'mean'),\n",
    "                                                     mean_size = ('size', 'mean'),\n",
    "                                                     mean_order = ('order_count', 'mean'),\n",
    "                                                     max_sec_in_bucket = ('seconds_in_bucket', 'max'), \n",
    "                                                     max_price = ('price', 'max'),\n",
    "                                                     max_size = ('size', 'max'),\n",
    "                                                     max_order = ('order_count', 'max'),\n",
    "                                                     min_sec_in_bucket = ('seconds_in_bucket', 'min'), \n",
    "                                                     min_price = ('price', 'min'),\n",
    "                                                     #min_size = ('size', 'min'),\n",
    "                                                     #min_order = ('order_count', 'min'),\n",
    "                                                     median_sec_in_bucket = ('seconds_in_bucket', 'median'), \n",
    "                                                     median_price = ('price', 'median'),\n",
    "                                                     median_size = ('size', 'median'),\n",
    "                                                     median_order = ('order_count', 'median')\n",
    "                                                    ).reset_index()\n",
    "    \n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:20:50.961875Z",
     "iopub.status.busy": "2025-10-02T14:20:50.961597Z",
     "iopub.status.idle": "2025-10-02T14:20:50.978920Z",
     "shell.execute_reply": "2025-10-02T14:20:50.978209Z",
     "shell.execute_reply.started": "2025-10-02T14:20:50.961851Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_stock_stat(stock_id : int, dataType = 'train'):\n",
    "    \n",
    "    book_subset, trade_subset = get_trade_and_book_by_stock_and_time_id(stock_id, dataType=dataType)\n",
    "    book_subset.sort_values(by=['time_id', 'seconds_in_bucket'])\n",
    "\n",
    "    ## book data processing\n",
    "    \n",
    "    book_subset['bas'] = (book_subset[['ask_price1', 'ask_price2']].min(axis = 1)\n",
    "                                / book_subset[['bid_price1', 'bid_price2']].max(axis = 1)\n",
    "                                - 1)                               \n",
    "\n",
    "    \n",
    "    book_subset['wap1'] = calculate_wap1(book_subset)\n",
    "    book_subset['wap2'] = calculate_wap2(book_subset)\n",
    "    \n",
    "    book_subset['log_return_bid_price1'] = np.log(book_subset['bid_price1'].pct_change() + 1)\n",
    "    book_subset['log_return_ask_price1'] = np.log(book_subset['ask_price1'].pct_change() + 1)\n",
    "    # book_subset['log_return_bid_price2'] = np.log(book_subset['bid_price2'].pct_change() + 1)\n",
    "    # book_subset['log_return_ask_price2'] = np.log(book_subset['ask_price2'].pct_change() + 1)\n",
    "    book_subset['log_return_bid_size1'] = np.log(book_subset['bid_size1'].pct_change() + 1)\n",
    "    book_subset['log_return_ask_size1'] = np.log(book_subset['ask_size1'].pct_change() + 1)\n",
    "    # book_subset['log_return_bid_size2'] = np.log(book_subset['bid_size2'].pct_change() + 1)\n",
    "    # book_subset['log_return_ask_size2'] = np.log(book_subset['ask_size2'].pct_change() + 1)\n",
    "    book_subset['log_ask_1_div_bid_1'] = np.log(book_subset['ask_price1'] / book_subset['bid_price1'])\n",
    "    book_subset['log_ask_1_div_bid_1_size'] = np.log(book_subset['ask_size1'] / book_subset['bid_size1'])\n",
    "    \n",
    "\n",
    "    book_subset['log_return1'] = (book_subset.groupby(by = ['time_id'])['wap1'].\n",
    "                                  apply(log_return).\n",
    "                                  reset_index(drop = True).\n",
    "                                  fillna(0)\n",
    "                                 )\n",
    "    book_subset['log_return2'] = (book_subset.groupby(by = ['time_id'])['wap2'].\n",
    "                                  apply(log_return).\n",
    "                                  reset_index(drop = True).\n",
    "                                  fillna(0)\n",
    "                                 )\n",
    "    \n",
    "    stock_stat = pd.merge(\n",
    "        book_subset.groupby(by = ['time_id'])['log_return1'].agg(realized_volatility).reset_index(),\n",
    "        book_subset.groupby(by = ['time_id'], as_index = False)['bas'].mean(),\n",
    "        on = ['time_id'],\n",
    "        how = 'left'\n",
    "    )\n",
    "    \n",
    "    stock_stat = pd.merge(\n",
    "        stock_stat,\n",
    "        book_subset.groupby(by = ['time_id'])['log_return2'].agg(realized_volatility).reset_index(),\n",
    "        on = ['time_id'],\n",
    "        how = 'left'\n",
    "    )\n",
    "    \n",
    "    stock_stat = pd.merge(\n",
    "        stock_stat,\n",
    "        book_subset.groupby(by = ['time_id'])['log_return_bid_price1'].agg(realized_volatility).reset_index(),\n",
    "        on = ['time_id'],\n",
    "        how = 'left'\n",
    "    )\n",
    "    stock_stat = pd.merge(\n",
    "        stock_stat,\n",
    "        book_subset.groupby(by = ['time_id'])['log_return_ask_price1'].agg(realized_volatility).reset_index(),\n",
    "        on = ['time_id'],\n",
    "        how = 'left'\n",
    "    )\n",
    "    stock_stat = pd.merge(\n",
    "        stock_stat,\n",
    "        book_subset.groupby(by = ['time_id'])['log_return_bid_size1'].agg(realized_volatility).reset_index(),\n",
    "        on = ['time_id'],\n",
    "        how = 'left'\n",
    "    )\n",
    "    stock_stat = pd.merge(\n",
    "        stock_stat,\n",
    "        book_subset.groupby(by = ['time_id'])['log_return_ask_size1'].agg(realized_volatility).reset_index(),\n",
    "        on = ['time_id'],\n",
    "        how = 'left'\n",
    "    )\n",
    "    \n",
    "    stock_stat = pd.merge(\n",
    "        stock_stat,\n",
    "        book_subset.groupby(by = ['time_id'])['log_ask_1_div_bid_1'].agg(realized_volatility).reset_index(),\n",
    "        on = ['time_id'],\n",
    "        how = 'left'\n",
    "    )\n",
    "    stock_stat = pd.merge(\n",
    "        stock_stat,\n",
    "        book_subset.groupby(by = ['time_id'])['log_ask_1_div_bid_1_size'].agg(realized_volatility).reset_index(),\n",
    "        on = ['time_id'],\n",
    "        how = 'left'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    stock_stat['stock_id'] = stock_id\n",
    "    \n",
    "    # Additional features that can be added. Referenced from https://www.kaggle.com/yus002/realized-volatility-prediction-lgbm-train/data\n",
    "    \n",
    "    # trade_subset_agg = get_agg_info(trade_subset)\n",
    "    \n",
    "    #     stock_stat = pd.merge(\n",
    "    #         stock_stat,\n",
    "    #         trade_subset_agg,\n",
    "    #         on = ['stock_id', 'time_id'],\n",
    "    #         how = 'left'\n",
    "    #     )\n",
    "    \n",
    "    ## trade data processing \n",
    "    \n",
    "    return stock_stat\n",
    "\n",
    "def get_data_set(stock_ids : list, dataType = 'train'):\n",
    "\n",
    "    stock_stat = Parallel(n_jobs=-1)(\n",
    "        delayed(get_stock_stat)(stock_id, dataType) \n",
    "        for stock_id in stock_ids\n",
    "    )\n",
    "    \n",
    "    stock_stat_df = pd.concat(stock_stat, ignore_index = True)\n",
    "\n",
    "    return stock_stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:20:50.980361Z",
     "iopub.status.busy": "2025-10-02T14:20:50.980089Z",
     "iopub.status.idle": "2025-10-02T14:20:50.994769Z",
     "shell.execute_reply": "2025-10-02T14:20:50.994079Z",
     "shell.execute_reply.started": "2025-10-02T14:20:50.980336Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:20:51.006289Z",
     "iopub.status.busy": "2025-10-02T14:20:51.005951Z",
     "iopub.status.idle": "2025-10-02T14:20:51.595297Z",
     "shell.execute_reply": "2025-10-02T14:20:51.594413Z",
     "shell.execute_reply.started": "2025-10-02T14:20:51.006257Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(94, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "book_stock_1, trade_stock_1 = get_trade_and_book_by_stock_and_time_id(1, 5)\n",
    "display(book_stock_1.shape)\n",
    "display(trade_stock_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:20:51.596812Z",
     "iopub.status.busy": "2025-10-02T14:20:51.596480Z",
     "iopub.status.idle": "2025-10-02T14:20:51.608419Z",
     "shell.execute_reply": "2025-10-02T14:20:51.607607Z",
     "shell.execute_reply.started": "2025-10-02T14:20:51.596786Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time_id",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "seconds_in_bucket",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "bid_price1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "ask_price1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "bid_price2",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "ask_price2",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "bid_size1",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "ask_size1",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "bid_size2",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "ask_size2",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "stock_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "e468811b-d00e-40ec-83f4-0af717f8ea2e",
       "rows": [
        [
         "0",
         "5",
         "0",
         "1.0007545",
         "1.0015419",
         "1.0006889",
         "1.0016074",
         "1",
         "25",
         "25",
         "100",
         "1"
        ],
        [
         "1",
         "5",
         "1",
         "1.0007545",
         "1.0016731",
         "1.0006889",
         "1.0017387",
         "26",
         "60",
         "25",
         "100",
         "1"
        ],
        [
         "2",
         "5",
         "2",
         "1.0007545",
         "1.0014106",
         "1.0006233",
         "1.0014763",
         "1",
         "25",
         "25",
         "125",
         "1"
        ],
        [
         "3",
         "5",
         "3",
         "1.0007545",
         "1.0015419",
         "1.0006889",
         "1.0016074",
         "125",
         "25",
         "126",
         "36",
         "1"
        ],
        [
         "4",
         "5",
         "4",
         "1.0007545",
         "1.0014763",
         "1.0006233",
         "1.0015419",
         "100",
         "100",
         "25",
         "25",
         "1"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>bid_price1</th>\n",
       "      <th>ask_price1</th>\n",
       "      <th>bid_price2</th>\n",
       "      <th>ask_price2</th>\n",
       "      <th>bid_size1</th>\n",
       "      <th>ask_size1</th>\n",
       "      <th>bid_size2</th>\n",
       "      <th>ask_size2</th>\n",
       "      <th>stock_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>1.001542</td>\n",
       "      <td>1.000689</td>\n",
       "      <td>1.001607</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>1.001673</td>\n",
       "      <td>1.000689</td>\n",
       "      <td>1.001739</td>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>1.001411</td>\n",
       "      <td>1.000623</td>\n",
       "      <td>1.001476</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>1.001542</td>\n",
       "      <td>1.000689</td>\n",
       "      <td>1.001607</td>\n",
       "      <td>125</td>\n",
       "      <td>25</td>\n",
       "      <td>126</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>1.001476</td>\n",
       "      <td>1.000623</td>\n",
       "      <td>1.001542</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_id  seconds_in_bucket  bid_price1  ask_price1  bid_price2  ask_price2  \\\n",
       "0        5                  0    1.000754    1.001542    1.000689    1.001607   \n",
       "1        5                  1    1.000754    1.001673    1.000689    1.001739   \n",
       "2        5                  2    1.000754    1.001411    1.000623    1.001476   \n",
       "3        5                  3    1.000754    1.001542    1.000689    1.001607   \n",
       "4        5                  4    1.000754    1.001476    1.000623    1.001542   \n",
       "\n",
       "   bid_size1  ask_size1  bid_size2  ask_size2  stock_id  \n",
       "0          1         25         25        100         1  \n",
       "1         26         60         25        100         1  \n",
       "2          1         25         25        125         1  \n",
       "3        125         25        126         36         1  \n",
       "4        100        100         25         25         1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_stock_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:20:51.609633Z",
     "iopub.status.busy": "2025-10-02T14:20:51.609387Z",
     "iopub.status.idle": "2025-10-02T14:20:51.622578Z",
     "shell.execute_reply": "2025-10-02T14:20:51.621729Z",
     "shell.execute_reply.started": "2025-10-02T14:20:51.609610Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time_id",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "seconds_in_bucket",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "price",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "size",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "order_count",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "stock_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d893f477-6388-4d5c-9c10-dd9eb8a0f5b4",
       "rows": [
        [
         "0",
         "5",
         "28",
         "1.0020802",
         "553",
         "11",
         "1"
        ],
        [
         "1",
         "5",
         "39",
         "1.0024604",
         "8",
         "3",
         "1"
        ],
        [
         "2",
         "5",
         "42",
         "1.0023081",
         "147",
         "4",
         "1"
        ],
        [
         "3",
         "5",
         "44",
         "1.0027884",
         "1",
         "1",
         "1"
        ],
        [
         "4",
         "5",
         "51",
         "1.0026572",
         "100",
         "2",
         "1"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>order_count</th>\n",
       "      <th>stock_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>1.002080</td>\n",
       "      <td>553</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>1.002460</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>1.002308</td>\n",
       "      <td>147</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>1.002788</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>1.002657</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_id  seconds_in_bucket     price  size  order_count  stock_id\n",
       "0        5                 28  1.002080   553           11         1\n",
       "1        5                 39  1.002460     8            3         1\n",
       "2        5                 42  1.002308   147            4         1\n",
       "3        5                 44  1.002788     1            1         1\n",
       "4        5                 51  1.002657   100            2         1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_stock_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:20:51.624182Z",
     "iopub.status.busy": "2025-10-02T14:20:51.623804Z",
     "iopub.status.idle": "2025-10-02T14:29:16.409263Z",
     "shell.execute_reply": "2025-10-02T14:29:16.408420Z",
     "shell.execute_reply.started": "2025-10-02T14:20:51.624146Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.52 s\n",
      "Wall time: 3min 16s\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time_id",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "log_return1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bas",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_return2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "log_return_bid_price1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_return_ask_price1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_return_bid_size1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "log_return_ask_size1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "log_ask_1_div_bid_1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_ask_1_div_bid_1_size",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stock_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "9e824495-cd3b-48c1-a5d1-0188ff8ab525",
       "rows": [
        [
         "0",
         "5",
         "0.0041146791172599435",
         "0.00085222325",
         "0.00410576481291803",
         "0.0026017528",
         "0.0024756119",
         "25.371833791009838",
         "29.77264194226755",
         "0.015250668",
         "47.1739814219773",
         "0"
        ],
        [
         "1",
         "11",
         "0.0012683619904927986",
         "0.00039428115",
         "0.0015072004260869977",
         "0.003793111",
         "0.0036853785",
         "17.55725551400241",
         "16.155778793753218",
         "0.0059993514",
         "39.85346369200729",
         "0"
        ],
        [
         "2",
         "16",
         "0.002719116611588031",
         "0.00072542595",
         "0.002468536988749982",
         "0.0016968006",
         "0.0017918042",
         "14.737647827102649",
         "11.275510807252953",
         "0.010191092",
         "29.314080816321948",
         "0"
        ],
        [
         "3",
         "31",
         "0.00262517608025175",
         "0.0008608391",
         "0.0027085139913048607",
         "0.0029922873",
         "0.002740129",
         "13.412586478778609",
         "9.77489211465719",
         "0.009908084",
         "26.98180765390695",
         "0"
        ],
        [
         "4",
         "62",
         "0.0019007686794087395",
         "0.00039725006",
         "0.001932414589494655",
         "0.0025359476",
         "0.0019263098",
         "23.797380739382973",
         "17.759397140335782",
         "0.005542528",
         "36.74681186932183",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>log_return1</th>\n",
       "      <th>bas</th>\n",
       "      <th>log_return2</th>\n",
       "      <th>log_return_bid_price1</th>\n",
       "      <th>log_return_ask_price1</th>\n",
       "      <th>log_return_bid_size1</th>\n",
       "      <th>log_return_ask_size1</th>\n",
       "      <th>log_ask_1_div_bid_1</th>\n",
       "      <th>log_ask_1_div_bid_1_size</th>\n",
       "      <th>stock_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>25.371834</td>\n",
       "      <td>29.772642</td>\n",
       "      <td>0.015251</td>\n",
       "      <td>47.173981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>17.557256</td>\n",
       "      <td>16.155779</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>39.853464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>14.737648</td>\n",
       "      <td>11.275511</td>\n",
       "      <td>0.010191</td>\n",
       "      <td>29.314081</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>13.412586</td>\n",
       "      <td>9.774892</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>26.981808</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>23.797381</td>\n",
       "      <td>17.759397</td>\n",
       "      <td>0.005543</td>\n",
       "      <td>36.746812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_id  log_return1       bas  log_return2  log_return_bid_price1  \\\n",
       "0        5     0.004115  0.000852     0.004106               0.002602   \n",
       "1       11     0.001268  0.000394     0.001507               0.003793   \n",
       "2       16     0.002719  0.000725     0.002469               0.001697   \n",
       "3       31     0.002625  0.000861     0.002709               0.002992   \n",
       "4       62     0.001901  0.000397     0.001932               0.002536   \n",
       "\n",
       "   log_return_ask_price1  log_return_bid_size1  log_return_ask_size1  \\\n",
       "0               0.002476             25.371834             29.772642   \n",
       "1               0.003685             17.557256             16.155779   \n",
       "2               0.001792             14.737648             11.275511   \n",
       "3               0.002740             13.412586              9.774892   \n",
       "4               0.001926             23.797381             17.759397   \n",
       "\n",
       "   log_ask_1_div_bid_1  log_ask_1_div_bid_1_size  stock_id  \n",
       "0             0.015251                 47.173981         0  \n",
       "1             0.005999                 39.853464         0  \n",
       "2             0.010191                 29.314081         0  \n",
       "3             0.009908                 26.981808         0  \n",
       "4             0.005543                 36.746812         0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_stock_stat_df = get_data_set(train.stock_id.unique(), dataType = 'train')\n",
    "train_stock_stat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:29:16.410906Z",
     "iopub.status.busy": "2025-10-02T14:29:16.410676Z",
     "iopub.status.idle": "2025-10-02T14:29:16.568313Z",
     "shell.execute_reply": "2025-10-02T14:29:16.567386Z",
     "shell.execute_reply.started": "2025-10-02T14:29:16.410881Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "stock_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "target",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "log_return1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bas",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_return2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "log_return_bid_price1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_return_ask_price1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_return_bid_size1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "log_return_ask_size1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "log_ask_1_div_bid_1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_ask_1_div_bid_1_size",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "68a14325-611f-4925-87b7-5523be1bded3",
       "rows": [
        [
         "0",
         "0",
         "5",
         "0.004135767",
         "0.0041146791172599435",
         "0.00085222325",
         "0.00410576481291803",
         "0.0026017528",
         "0.0024756119",
         "25.371833791009838",
         "29.77264194226755",
         "0.015250668",
         "47.1739814219773"
        ],
        [
         "1",
         "0",
         "11",
         "0.001444587",
         "0.0012683619904927986",
         "0.00039428115",
         "0.0015072004260869977",
         "0.003793111",
         "0.0036853785",
         "17.55725551400241",
         "16.155778793753218",
         "0.0059993514",
         "39.85346369200729"
        ],
        [
         "2",
         "0",
         "16",
         "0.002168189",
         "0.002719116611588031",
         "0.00072542595",
         "0.002468536988749982",
         "0.0016968006",
         "0.0017918042",
         "14.737647827102649",
         "11.275510807252953",
         "0.010191092",
         "29.314080816321948"
        ],
        [
         "3",
         "0",
         "31",
         "0.002195261",
         "0.00262517608025175",
         "0.0008608391",
         "0.0027085139913048607",
         "0.0029922873",
         "0.002740129",
         "13.412586478778609",
         "9.77489211465719",
         "0.009908084",
         "26.98180765390695"
        ],
        [
         "4",
         "0",
         "62",
         "0.001747216",
         "0.0019007686794087395",
         "0.00039725006",
         "0.001932414589494655",
         "0.0025359476",
         "0.0019263098",
         "23.797380739382973",
         "17.759397140335782",
         "0.005542528",
         "36.74681186932183"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>log_return1</th>\n",
       "      <th>bas</th>\n",
       "      <th>log_return2</th>\n",
       "      <th>log_return_bid_price1</th>\n",
       "      <th>log_return_ask_price1</th>\n",
       "      <th>log_return_bid_size1</th>\n",
       "      <th>log_return_ask_size1</th>\n",
       "      <th>log_ask_1_div_bid_1</th>\n",
       "      <th>log_ask_1_div_bid_1_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>25.371834</td>\n",
       "      <td>29.772642</td>\n",
       "      <td>0.015251</td>\n",
       "      <td>47.173981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>17.557256</td>\n",
       "      <td>16.155779</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>39.853464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>14.737648</td>\n",
       "      <td>11.275511</td>\n",
       "      <td>0.010191</td>\n",
       "      <td>29.314081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>13.412586</td>\n",
       "      <td>9.774892</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>26.981808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>23.797381</td>\n",
       "      <td>17.759397</td>\n",
       "      <td>0.005543</td>\n",
       "      <td>36.746812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  time_id    target  log_return1       bas  log_return2  \\\n",
       "0         0        5  0.004136     0.004115  0.000852     0.004106   \n",
       "1         0       11  0.001445     0.001268  0.000394     0.001507   \n",
       "2         0       16  0.002168     0.002719  0.000725     0.002469   \n",
       "3         0       31  0.002195     0.002625  0.000861     0.002709   \n",
       "4         0       62  0.001747     0.001901  0.000397     0.001932   \n",
       "\n",
       "   log_return_bid_price1  log_return_ask_price1  log_return_bid_size1  \\\n",
       "0               0.002602               0.002476             25.371834   \n",
       "1               0.003793               0.003685             17.557256   \n",
       "2               0.001697               0.001792             14.737648   \n",
       "3               0.002992               0.002740             13.412586   \n",
       "4               0.002536               0.001926             23.797381   \n",
       "\n",
       "   log_return_ask_size1  log_ask_1_div_bid_1  log_ask_1_div_bid_1_size  \n",
       "0             29.772642             0.015251                 47.173981  \n",
       "1             16.155779             0.005999                 39.853464  \n",
       "2             11.275511             0.010191                 29.314081  \n",
       "3              9.774892             0.009908                 26.981808  \n",
       "4             17.759397             0.005543                 36.746812  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_set = pd.merge(train, train_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left')\n",
    "train_data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:29:16.569460Z",
     "iopub.status.busy": "2025-10-02T14:29:16.569245Z",
     "iopub.status.idle": "2025-10-02T14:29:16.602542Z",
     "shell.execute_reply": "2025-10-02T14:29:16.601703Z",
     "shell.execute_reply.started": "2025-10-02T14:29:16.569439Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 428932 entries, 0 to 428931\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   stock_id                  428932 non-null  int64  \n",
      " 1   time_id                   428932 non-null  int64  \n",
      " 2   target                    428932 non-null  float64\n",
      " 3   log_return1               428932 non-null  float64\n",
      " 4   bas                       428932 non-null  float32\n",
      " 5   log_return2               428932 non-null  float64\n",
      " 6   log_return_bid_price1     428932 non-null  float32\n",
      " 7   log_return_ask_price1     428932 non-null  float32\n",
      " 8   log_return_bid_size1      428932 non-null  float64\n",
      " 9   log_return_ask_size1      428932 non-null  float64\n",
      " 10  log_ask_1_div_bid_1       428932 non-null  float32\n",
      " 11  log_ask_1_div_bid_1_size  428932 non-null  float64\n",
      "dtypes: float32(4), float64(6), int64(2)\n",
      "memory usage: 32.7 MB\n"
     ]
    }
   ],
   "source": [
    "train_data_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:29:16.603979Z",
     "iopub.status.busy": "2025-10-02T14:29:16.603649Z",
     "iopub.status.idle": "2025-10-02T14:29:16.712563Z",
     "shell.execute_reply": "2025-10-02T14:29:16.711782Z",
     "shell.execute_reply.started": "2025-10-02T14:29:16.603942Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 65.4 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time_id",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "log_return1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bas",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_return2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "log_return_bid_price1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_return_ask_price1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_return_bid_size1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "log_return_ask_size1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "log_ask_1_div_bid_1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_ask_1_div_bid_1_size",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stock_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "8ba4fd13-3175-4e4c-82a5-0d7eeb7f4136",
       "rows": [
        [
         "0",
         "4",
         "0.00027272192664706005",
         "0.0005572637",
         "0.00026335691668052274",
         "0.0",
         "4.9232225e-05",
         "1.1590214164636696",
         "1.6094379124341005",
         "0.00096577575",
         "2.6774726903844197",
         "0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>log_return1</th>\n",
       "      <th>bas</th>\n",
       "      <th>log_return2</th>\n",
       "      <th>log_return_bid_price1</th>\n",
       "      <th>log_return_ask_price1</th>\n",
       "      <th>log_return_bid_size1</th>\n",
       "      <th>log_return_ask_size1</th>\n",
       "      <th>log_ask_1_div_bid_1</th>\n",
       "      <th>log_ask_1_div_bid_1_size</th>\n",
       "      <th>stock_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>1.159021</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>2.677473</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_id  log_return1       bas  log_return2  log_return_bid_price1  \\\n",
       "0        4     0.000273  0.000557     0.000263                    0.0   \n",
       "\n",
       "   log_return_ask_price1  log_return_bid_size1  log_return_ask_size1  \\\n",
       "0               0.000049              1.159021              1.609438   \n",
       "\n",
       "   log_ask_1_div_bid_1  log_ask_1_div_bid_1_size  stock_id  \n",
       "0             0.000966                  2.677473         0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_stock_stat_df = get_data_set(test['stock_id'].unique(), dataType = 'test')\n",
    "test_stock_stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:29:16.713788Z",
     "iopub.status.busy": "2025-10-02T14:29:16.713537Z",
     "iopub.status.idle": "2025-10-02T14:29:16.731435Z",
     "shell.execute_reply": "2025-10-02T14:29:16.730668Z",
     "shell.execute_reply.started": "2025-10-02T14:29:16.713764Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "stock_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "row_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "log_return1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "bas",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_return2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "log_return_bid_price1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_return_ask_price1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_return_bid_size1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "log_return_ask_size1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "log_ask_1_div_bid_1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "log_ask_1_div_bid_1_size",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d5916dad-cf33-47ea-8762-769718243bfe",
       "rows": [
        [
         "0",
         "0",
         "4",
         "0-4",
         "0.00027272192664706005",
         "0.0005572637",
         "0.00026335691668052274",
         "0.0",
         "4.9232225e-05",
         "1.1590214164636696",
         "1.6094379124341005",
         "0.00096577575",
         "2.6774726903844197"
        ],
        [
         "1",
         "0",
         "32",
         "0-32",
         "-999.0",
         "-999.0",
         "-999.0",
         "-999.0",
         "-999.0",
         "-999.0",
         "-999.0",
         "-999.0",
         "-999.0"
        ],
        [
         "2",
         "0",
         "34",
         "0-34",
         "-999.0",
         "-999.0",
         "-999.0",
         "-999.0",
         "-999.0",
         "-999.0",
         "-999.0",
         "-999.0",
         "-999.0"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>log_return1</th>\n",
       "      <th>bas</th>\n",
       "      <th>log_return2</th>\n",
       "      <th>log_return_bid_price1</th>\n",
       "      <th>log_return_ask_price1</th>\n",
       "      <th>log_return_bid_size1</th>\n",
       "      <th>log_return_ask_size1</th>\n",
       "      <th>log_ask_1_div_bid_1</th>\n",
       "      <th>log_ask_1_div_bid_1_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>1.159021</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>2.677473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0-32</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0-34</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  time_id row_id  log_return1         bas  log_return2  \\\n",
       "0         0        4    0-4     0.000273    0.000557     0.000263   \n",
       "1         0       32   0-32  -999.000000 -999.000000  -999.000000   \n",
       "2         0       34   0-34  -999.000000 -999.000000  -999.000000   \n",
       "\n",
       "   log_return_bid_price1  log_return_ask_price1  log_return_bid_size1  \\\n",
       "0                    0.0               0.000049              1.159021   \n",
       "1                 -999.0            -999.000000           -999.000000   \n",
       "2                 -999.0            -999.000000           -999.000000   \n",
       "\n",
       "   log_return_ask_size1  log_ask_1_div_bid_1  log_ask_1_div_bid_1_size  \n",
       "0              1.609438             0.000966                  2.677473  \n",
       "1           -999.000000          -999.000000               -999.000000  \n",
       "2           -999.000000          -999.000000               -999.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_set = pd.merge(test, test_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left')\n",
    "test_data_set.fillna(-999, inplace=True)\n",
    "test_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:29:16.732588Z",
     "iopub.status.busy": "2025-10-02T14:29:16.732381Z",
     "iopub.status.idle": "2025-10-02T14:29:16.830739Z",
     "shell.execute_reply": "2025-10-02T14:29:16.830099Z",
     "shell.execute_reply.started": "2025-10-02T14:29:16.732567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train_data_set.to_pickle('train_features_df.pickle')\n",
    "# test_data_set.to_pickle('test_features_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:29:50.887035Z",
     "iopub.status.busy": "2025-10-02T14:29:50.886426Z",
     "iopub.status.idle": "2025-10-02T14:29:51.047044Z",
     "shell.execute_reply": "2025-10-02T14:29:51.046065Z",
     "shell.execute_reply.started": "2025-10-02T14:29:50.886946Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:29:56.849810Z",
     "iopub.status.busy": "2025-10-02T14:29:56.849509Z",
     "iopub.status.idle": "2025-10-02T14:29:56.870791Z",
     "shell.execute_reply": "2025-10-02T14:29:56.869935Z",
     "shell.execute_reply.started": "2025-10-02T14:29:56.849784Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((428932, 9), (428932,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_display = train_data_set.drop(['stock_id', 'time_id', 'target'], axis = 1)\n",
    "X = X_display.values\n",
    "y = train_data_set['target'].values\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:37:26.144898Z",
     "iopub.status.busy": "2025-10-02T14:37:26.144605Z",
     "iopub.status.idle": "2025-10-02T14:37:26.161507Z",
     "shell.execute_reply": "2025-10-02T14:37:26.160775Z",
     "shell.execute_reply.started": "2025-10-02T14:37:26.144872Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((343145, 9), (85787, 9), (343145,), (85787,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=Config.seed, shuffle=False)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T14:30:09.047429Z",
     "iopub.status.busy": "2025-10-02T14:30:09.047120Z",
     "iopub.status.idle": "2025-10-02T14:30:09.050939Z",
     "shell.execute_reply": "2025-10-02T14:30:09.050109Z",
     "shell.execute_reply.started": "2025-10-02T14:30:09.047403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rs = Config.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the Decision Tree prediction: R2 score: 0.714459, RMSPE: 0.335916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# dt = DecisionTreeRegressor(random_state=42)\n",
    "dt = DecisionTreeRegressor(\n",
    "    max_depth=4,      \n",
    "    random_state=42\n",
    ")\n",
    "dt.fit(X_train, y_train)\n",
    "preds = dt.predict(X_test)\n",
    "R2 = round(r2_score(y_true=y_test, y_pred=preds), 6)\n",
    "RMSPE = round(rmspe(y_true=y_test, y_pred=preds), 6)\n",
    "print(f'Performance of the Decision Tree prediction: R2 score: {R2}, RMSPE: {RMSPE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bagging...\n",
      "Bagging completed in 72.44 seconds\n",
      "Training RandomForest...\n",
      "RandomForest completed in 169.00 seconds\n",
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON RESULTS\n",
      "================================================================================\n",
      "       Model     R2   RMSE  RMSPE  Training_Time  CV_Mean_R2  CV_Std  Overfitting_Gap\n",
      "     Bagging 0.7636 0.0014 0.3135          72.44      0.7675  0.0062           0.0110\n",
      "RandomForest 0.7618 0.0014 0.3159         169.00      0.7657  0.0062           0.0117\n",
      "\n",
      "==================================================\n",
      "PERFORMANCE RANKINGS\n",
      "==================================================\n",
      "R2 Score Ranking:\n",
      "1. Bagging: 0.7636\n",
      "2. RandomForest: 0.7618\n",
      "\n",
      "RMSPE Ranking (lower is better):\n",
      "1. Bagging: 0.3135\n",
      "2. RandomForest: 0.3159\n",
      "\n",
      "Stability Ranking (CV Std, lower is better):\n",
      "1. Bagging: 0.0062\n",
      "2. RandomForest: 0.0062\n",
      "\n",
      "Overfitting Resistance Ranking (gap, lower is better):\n",
      "1. Bagging: 0.011\n",
      "2. RandomForest: 0.0117\n",
      "\n",
      "==================================================\n",
      "COMPREHENSIVE ANALYSIS\n",
      "==================================================\n",
      "Best R2: Bagging (0.7636)\n",
      "Best RMSPE: Bagging (0.3135)\n",
      "Fastest Training: Bagging (72.44s)\n",
      "Most Stable: Bagging (CV Std: 0.0062)\n",
      "Least Overfitting: Bagging (Gap: 0.011)\n",
      "\n",
      "==================================================\n",
      "VALIDATION OF TABLE CHARACTERISTICS\n",
      "==================================================\n",
      "Noise Sensitivity (based on CV stability):\n",
      "- Bagging: Low\n",
      "- RandomForest: Low\n",
      "\n",
      "Overfitting Risk:\n",
      "- Bagging: Low\n",
      "- RandomForest: Low\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "models = {\n",
    "    # 'AdaBoost': AdaBoostRegressor(\n",
    "    #     estimator=DecisionTreeRegressor(max_depth=4, random_state=42),\n",
    "    #     n_estimators=100,\n",
    "    #     learning_rate=0.1,\n",
    "    #     random_state=42\n",
    "    # ),\n",
    "    'Bagging': BaggingRegressor(\n",
    "        estimator=DecisionTreeRegressor(max_depth=4, random_state=42),\n",
    "        n_estimators=100,\n",
    "        # max_samples=0.8,\n",
    "        # max_features=0.8,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'RandomForest': RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=4,\n",
    "        # max_features='sqrt', \n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "   \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmspe_val = rmspe(y_test, y_pred)\n",
    "    \n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    overfitting_gap = train_r2 - r2\n",
    "    \n",
    "\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'R2': round(r2, 4),\n",
    "        'RMSE': round(rmse, 4),\n",
    "        'RMSPE': round(rmspe_val, 4),\n",
    "        'Training_Time': round(training_time, 2),\n",
    "        'CV_Mean_R2': round(cv_mean, 4),\n",
    "        'CV_Std': round(cv_std, 4),\n",
    "        'Overfitting_Gap': round(overfitting_gap, 4)\n",
    "    })\n",
    "    \n",
    "    print(f\"{name} completed in {training_time:.2f} seconds\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PERFORMANCE RANKINGS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "r2_rank = results_df[['Model', 'R2']].sort_values('R2', ascending=False)\n",
    "print(\"R2 Score Ranking:\")\n",
    "for i, (_, row) in enumerate(r2_rank.iterrows(), 1):\n",
    "    print(f\"{i}. {row['Model']}: {row['R2']}\")\n",
    "\n",
    "rmspe_rank = results_df[['Model', 'RMSPE']].sort_values('RMSPE')\n",
    "print(\"\\nRMSPE Ranking (lower is better):\")\n",
    "for i, (_, row) in enumerate(rmspe_rank.iterrows(), 1):\n",
    "    print(f\"{i}. {row['Model']}: {row['RMSPE']}\")\n",
    "\n",
    "\n",
    "stability_rank = results_df[['Model', 'CV_Std']].sort_values('CV_Std')\n",
    "print(\"\\nStability Ranking (CV Std, lower is better):\")\n",
    "for i, (_, row) in enumerate(stability_rank.iterrows(), 1):\n",
    "    print(f\"{i}. {row['Model']}: {row['CV_Std']}\")\n",
    "\n",
    "\n",
    "overfit_rank = results_df[['Model', 'Overfitting_Gap']].sort_values('Overfitting_Gap')\n",
    "print(\"\\nOverfitting Resistance Ranking (gap, lower is better):\")\n",
    "for i, (_, row) in enumerate(overfit_rank.iterrows(), 1):\n",
    "    print(f\"{i}. {row['Model']}: {row['Overfitting_Gap']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPREHENSIVE ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "best_r2_model = results_df.loc[results_df['R2'].idxmax()]\n",
    "best_rmspe_model = results_df.loc[results_df['RMSPE'].idxmin()]\n",
    "fastest_model = results_df.loc[results_df['Training_Time'].idxmin()]\n",
    "most_stable_model = results_df.loc[results_df['CV_Std'].idxmin()]\n",
    "least_overfitting_model = results_df.loc[results_df['Overfitting_Gap'].idxmin()]\n",
    "\n",
    "print(f\"Best R2: {best_r2_model['Model']} ({best_r2_model['R2']})\")\n",
    "print(f\"Best RMSPE: {best_rmspe_model['Model']} ({best_rmspe_model['RMSPE']})\")\n",
    "print(f\"Fastest Training: {fastest_model['Model']} ({fastest_model['Training_Time']}s)\")\n",
    "print(f\"Most Stable: {most_stable_model['Model']} (CV Std: {most_stable_model['CV_Std']})\")\n",
    "print(f\"Least Overfitting: {least_overfitting_model['Model']} (Gap: {least_overfitting_model['Overfitting_Gap']})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"VALIDATION OF TABLE CHARACTERISTICS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"Noise Sensitivity (based on CV stability):\")\n",
    "for _, row in stability_rank.iterrows():\n",
    "    sensitivity = \"Low\" if row['CV_Std'] < 0.05 else \"Moderate\" if row['CV_Std'] < 0.1 else \"High\"\n",
    "    print(f\"- {row['Model']}: {sensitivity}\")\n",
    "\n",
    "print(\"\\nOverfitting Risk:\")\n",
    "for _, row in overfit_rank.iterrows():\n",
    "    risk = \"Low\" if row['Overfitting_Gap'] < 0.05 else \"Moderate\" if row['Overfitting_Gap'] < 0.1 else \"High\"\n",
    "    print(f\"- {row['Model']}: {risk}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 2344753,
     "sourceId": 27233,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30097,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
},
{
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "# Optuna Tuned XGBoost"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 42,
  "metadata": {
   "execution": {
    "iopub.execute_input": "2025-10-14T16:18:11.708171Z",
    "iopub.status.busy": "2025-10-14T16:18:11.707840Z",
    "iopub.status.idle": "2025-10-14T16:18:11.715789Z",
    "shell.execute_reply": "2025-10-14T16:18:11.715006Z",
    "shell.execute_reply.started": "2025-10-14T16:18:11.708140Z"
   }
  },
  "outputs": [],
  "source": [
   "def objective(trial):\n",
   "    \n",
   "    def rmspe(y_true, y_pred):\n",
   "        return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
   "    \n",
   "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs, shuffle=False)\n",
   "    valid = [(X_test, y_test)]\n",
   "    \n",
   "    param = {\n",
   "        \"device\": \"gpu\",\n",
   "        \"metric\": \"rmse\",\n",
   "        \"verbosity\": -1,\n",
   "        'learning_rate':trial.suggest_loguniform('learning_rate', 0.005, 0.5),\n",
   "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 500),\n",
   "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
   "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
   "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
   "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 4000),\n",
   "#         \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 100000, 700000),\n",
   "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
   "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
   "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
   "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100)}\n",
   "\n",
   "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"rmse\")\n",
   "    model = XGBRegressor(**param)\n",
   "    \n",
   "    model.fit(X_train, y_train, eval_set=valid, verbose=False, callbacks=[pruning_callback], early_stopping_rounds=100)\n",
   "\n",
   "    preds = model.predict(X_test)\n",
   "    \n",
   "    rmspe = rmspe(y_test, preds)\n",
   "    return rmspe"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 43,
  "metadata": {
   "_kg_hide-output": true,
   "execution": {
    "iopub.execute_input": "2025-10-14T16:18:17.516031Z",
    "iopub.status.busy": "2025-10-14T16:18:17.515693Z",
    "iopub.status.idle": "2025-10-14T16:37:54.362353Z",
    "shell.execute_reply": "2025-10-14T16:37:54.361643Z",
    "shell.execute_reply.started": "2025-10-14T16:18:17.515994Z"
   },
   "scrolled": true
  },
  "outputs": [
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:18:17,518]\u001b[0m A new study created in memory with name: no-name-6f4962e0-b41a-4c0c-a5b0-c5587b6d6fb4\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=6.740376521617552e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.740376521617552e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.0003449997477243431, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0003449997477243431\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9682463621690002, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9682463621690002\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6636565183690672, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6636565183690672\n",
     "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:18:27,518]\u001b[0m Trial 0 finished with value: 0.28798153505177665 and parameters: {'learning_rate': 0.11687051508507791, 'max_depth': 41, 'lambda_l1': 0.0003449997477243431, 'lambda_l2': 6.740376521617552e-08, 'num_leaves': 174, 'n_estimators': 1190, 'feature_fraction': 0.6636565183690672, 'bagging_fraction': 0.9682463621690002, 'bagging_freq': 3, 'min_child_samples': 71}. Best is trial 0 with value: 0.28798153505177665.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.7123992013302956, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7123992013302956\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.004882631689484558, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004882631689484558\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.47645117861656, subsample=1.0 will be ignored. Current value: bagging_fraction=0.47645117861656\n",
     "[LightGBM] [Warning] feature_fraction is set=0.5891207815773021, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5891207815773021\n",
     "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:18:35,065]\u001b[0m Trial 1 finished with value: 0.28646098277543214 and parameters: {'learning_rate': 0.037233338666322426, 'max_depth': 156, 'lambda_l1': 0.004882631689484558, 'lambda_l2': 0.7123992013302956, 'num_leaves': 129, 'n_estimators': 3690, 'feature_fraction': 0.5891207815773021, 'bagging_fraction': 0.47645117861656, 'bagging_freq': 4, 'min_child_samples': 90}. Best is trial 1 with value: 0.28646098277543214.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=3.410691050888197e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.410691050888197e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.0007997808177016752, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007997808177016752\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8906772502666553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8906772502666553\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7394522728734008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7394522728734008\n",
     "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:18:39,448]\u001b[0m Trial 2 finished with value: 0.28728935437818187 and parameters: {'learning_rate': 0.09185179140892959, 'max_depth': 13, 'lambda_l1': 0.0007997808177016752, 'lambda_l2': 3.410691050888197e-07, 'num_leaves': 103, 'n_estimators': 518, 'feature_fraction': 0.7394522728734008, 'bagging_fraction': 0.8906772502666553, 'bagging_freq': 5, 'min_child_samples': 45}. Best is trial 1 with value: 0.28646098277543214.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.002773340264450176, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002773340264450176\n",
     "[LightGBM] [Warning] lambda_l1 is set=5.575805689043948e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.575805689043948e-05\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8252723925409418, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8252723925409418\n",
     "[LightGBM] [Warning] feature_fraction is set=0.9915096393919126, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9915096393919126\n",
     "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:18:43,144]\u001b[0m Trial 3 finished with value: 0.2875894067771836 and parameters: {'learning_rate': 0.09298549045834503, 'max_depth': 312, 'lambda_l1': 5.575805689043948e-05, 'lambda_l2': 0.002773340264450176, 'num_leaves': 77, 'n_estimators': 3221, 'feature_fraction': 0.9915096393919126, 'bagging_fraction': 0.8252723925409418, 'bagging_freq': 6, 'min_child_samples': 84}. Best is trial 1 with value: 0.28646098277543214.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=7.783031714151519e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.783031714151519e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=1.2019632680464236e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2019632680464236e-06\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.4859886000651538, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4859886000651538\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6737481259017697, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6737481259017697\n",
     "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:18:47,372]\u001b[0m Trial 4 finished with value: 0.28591438162011645 and parameters: {'learning_rate': 0.13913499428691808, 'max_depth': 96, 'lambda_l1': 1.2019632680464236e-06, 'lambda_l2': 7.783031714151519e-08, 'num_leaves': 4, 'n_estimators': 567, 'feature_fraction': 0.6737481259017697, 'bagging_fraction': 0.4859886000651538, 'bagging_freq': 5, 'min_child_samples': 58}. Best is trial 4 with value: 0.28591438162011645.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.6164696115530893e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6164696115530893e-05\n",
     "[LightGBM] [Warning] lambda_l1 is set=6.140463745930106e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.140463745930106e-07\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.7248344568758025, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7248344568758025\n",
     "[LightGBM] [Warning] feature_fraction is set=0.622870775663678, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.622870775663678\n",
     "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:18:47,998]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:18:48,634]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:18:49,256]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:18:49,990]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:18:50,557]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:18:51,357]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:18:53,111]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 29.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:18:53,698]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:18:59,550]\u001b[0m Trial 13 finished with value: 0.2869687332185955 and parameters: {'learning_rate': 0.21720503616369088, 'max_depth': 217, 'lambda_l1': 0.03167571271325941, 'lambda_l2': 4.870974890273244, 'num_leaves': 225, 'n_estimators': 3925, 'feature_fraction': 0.8254610455004813, 'bagging_fraction': 0.593149788429101, 'bagging_freq': 3, 'min_child_samples': 37}. Best is trial 4 with value: 0.28591438162011645.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=4.5003681444890326e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.5003681444890326e-05\n",
     "[LightGBM] [Warning] lambda_l1 is set=6.102735562349727e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.102735562349727e-07\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.48541625210929534, subsample=1.0 will be ignored. Current value: bagging_fraction=0.48541625210929534\n",
     "[LightGBM] [Warning] feature_fraction is set=0.5694940946717001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5694940946717001\n",
     "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:19:00,115]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:01,461]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 29.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:02,158]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:02,795]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:03,435]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:07,582]\u001b[0m Trial 19 finished with value: 0.28707515128131106 and parameters: {'learning_rate': 0.1474106857854468, 'max_depth': 239, 'lambda_l1': 0.0013974185042613788, 'lambda_l2': 0.22401551041666068, 'num_leaves': 114, 'n_estimators': 2559, 'feature_fraction': 0.8533767255342731, 'bagging_fraction': 0.4525959524721359, 'bagging_freq': 2, 'min_child_samples': 59}. Best is trial 4 with value: 0.28591438162011645.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.0005011426438950868, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005011426438950868\n",
     "[LightGBM] [Warning] lambda_l1 is set=1.8171648189492497e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8171648189492497e-05\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.523810182681185, subsample=1.0 will be ignored. Current value: bagging_fraction=0.523810182681185\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6096737004826306, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6096737004826306\n",
     "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:19:08,557]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 29.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:11,052]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 43.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:11,761]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:13,500]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 32.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:14,317]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:14,981]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:20,591]\u001b[0m Trial 26 finished with value: 0.28923397141825347 and parameters: {'learning_rate': 0.12562649083641045, 'max_depth': 148, 'lambda_l1': 0.0029009017227925264, 'lambda_l2': 0.01628289327891535, 'num_leaves': 232, 'n_estimators': 2674, 'feature_fraction': 0.653211937893543, 'bagging_fraction': 0.6671377310369674, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 4 with value: 0.28591438162011645.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=8.011915835547478, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.011915835547478\n",
     "[LightGBM] [Warning] lambda_l1 is set=5.762979762422468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.762979762422468\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.4154935395910805, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4154935395910805\n",
     "[LightGBM] [Warning] feature_fraction is set=0.9208725892188389, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9208725892188389\n",
     "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:19:21,204]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:21,882]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:22,633]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:23,810]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 30.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:28,486]\u001b[0m Trial 31 finished with value: 0.28976819339684984 and parameters: {'learning_rate': 0.16087372004833414, 'max_depth': 262, 'lambda_l1': 0.0020797311786508645, 'lambda_l2': 0.40797096307675285, 'num_leaves': 163, 'n_estimators': 2446, 'feature_fraction': 0.8648663466946444, 'bagging_fraction': 0.4465981130000833, 'bagging_freq': 2, 'min_child_samples': 59}. Best is trial 4 with value: 0.28591438162011645.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.07780024459564701, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07780024459564701\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.002156995006457127, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002156995006457127\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.49252100611468774, subsample=1.0 will be ignored. Current value: bagging_fraction=0.49252100611468774\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7154522608447846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7154522608447846\n",
     "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:19:29,167]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:30,410]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:31,006]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:31,668]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:32,353]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:36,634]\u001b[0m Trial 37 finished with value: 0.28531781574642806 and parameters: {'learning_rate': 0.17237329067775112, 'max_depth': 299, 'lambda_l1': 0.0198499343519225, 'lambda_l2': 3.8552839562367756, 'num_leaves': 112, 'n_estimators': 1931, 'feature_fraction': 0.6861268010119852, 'bagging_fraction': 0.4015652274147308, 'bagging_freq': 3, 'min_child_samples': 82}. Best is trial 37 with value: 0.28531781574642806.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=5.1466366961702485, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.1466366961702485\n",
     "[LightGBM] [Warning] lambda_l1 is set=1.1131597604653096, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1131597604653096\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.4158058755129482, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4158058755129482\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6702195920339703, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6702195920339703\n",
     "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:19:37,310]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:38,658]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:39,431]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:40,563]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:43,564]\u001b[0m Trial 42 finished with value: 0.28560327248253203 and parameters: {'learning_rate': 0.25117292020172893, 'max_depth': 6, 'lambda_l1': 0.017121391291371732, 'lambda_l2': 4.666165530356962, 'num_leaves': 114, 'n_estimators': 1339, 'feature_fraction': 0.7897820256987836, 'bagging_fraction': 0.42746810975220234, 'bagging_freq': 3, 'min_child_samples': 62}. Best is trial 37 with value: 0.28531781574642806.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=8.455014674452412, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.455014674452412\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.021127767186850922, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.021127767186850922\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.4280633749371174, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4280633749371174\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6933864983607787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6933864983607787\n",
     "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:19:44,549]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:45,708]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:46,500]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:47,247]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:47,931]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:48,494]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:49,524]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:50,216]\u001b[0m Trial 50 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:54,943]\u001b[0m Trial 51 finished with value: 0.2865797770708367 and parameters: {'learning_rate': 0.1357980015178658, 'max_depth': 265, 'lambda_l1': 0.014873043270254335, 'lambda_l2': 0.13672890634850718, 'num_leaves': 141, 'n_estimators': 1286, 'feature_fraction': 0.8617375354118756, 'bagging_fraction': 0.44599464905119796, 'bagging_freq': 2, 'min_child_samples': 59}. Best is trial 37 with value: 0.28531781574642806.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.008484832775713658, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.008484832775713658\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.018408467885512363, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.018408467885512363\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.4312525264267452, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4312525264267452\n",
     "[LightGBM] [Warning] feature_fraction is set=0.8372631982433222, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8372631982433222\n",
     "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:19:55,625]\u001b[0m Trial 52 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:56,931]\u001b[0m Trial 53 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:58,247]\u001b[0m Trial 54 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:58,851]\u001b[0m Trial 55 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:19:59,533]\u001b[0m Trial 56 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:03,792]\u001b[0m Trial 57 finished with value: 0.2874400574561271 and parameters: {'learning_rate': 0.2482829377937557, 'max_depth': 292, 'lambda_l1': 0.014867462320267557, 'lambda_l2': 2.7677319243173937, 'num_leaves': 141, 'n_estimators': 290, 'feature_fraction': 0.9015300480593729, 'bagging_fraction': 0.46987240768910304, 'bagging_freq': 2, 'min_child_samples': 78}. Best is trial 37 with value: 0.28531781574642806.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.5973986275908273, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5973986275908273\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.5683048575259212, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5683048575259212\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.42774814709928377, subsample=1.0 will be ignored. Current value: bagging_fraction=0.42774814709928377\n",
     "[LightGBM] [Warning] feature_fraction is set=0.9367774883525848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9367774883525848\n",
     "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:20:04,504]\u001b[0m Trial 58 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:05,485]\u001b[0m Trial 59 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:06,190]\u001b[0m Trial 60 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:07,366]\u001b[0m Trial 61 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:08,141]\u001b[0m Trial 62 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:08,760]\u001b[0m Trial 63 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:12,635]\u001b[0m Trial 64 finished with value: 0.2897950355979398 and parameters: {'learning_rate': 0.1623211058717853, 'max_depth': 197, 'lambda_l1': 0.0013849879200252737, 'lambda_l2': 0.038538718725713864, 'num_leaves': 115, 'n_estimators': 1611, 'feature_fraction': 0.8321409744850783, 'bagging_fraction': 0.9141130077944413, 'bagging_freq': 3, 'min_child_samples': 67}. Best is trial 37 with value: 0.28531781574642806.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.009132896890968644, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.009132896890968644\n",
     "[LightGBM] [Warning] lambda_l1 is set=2.1141041961403692e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1141041961403692e-06\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.450778195968056, subsample=1.0 will be ignored. Current value: bagging_fraction=0.450778195968056\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7684981712987933, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7684981712987933\n",
     "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:20:13,283]\u001b[0m Trial 65 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:14,038]\u001b[0m Trial 66 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:14,674]\u001b[0m Trial 67 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:16,002]\u001b[0m Trial 68 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:17,304]\u001b[0m Trial 69 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:17,976]\u001b[0m Trial 70 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:21,060]\u001b[0m Trial 71 finished with value: 0.28911765818530444 and parameters: {'learning_rate': 0.16607350589884554, 'max_depth': 20, 'lambda_l1': 0.011039668386329003, 'lambda_l2': 3.679249180739487e-08, 'num_leaves': 93, 'n_estimators': 527, 'feature_fraction': 0.7323814590465819, 'bagging_fraction': 0.6580118244188511, 'bagging_freq': 5, 'min_child_samples': 37}. Best is trial 37 with value: 0.28531781574642806.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=2.145802672205613e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.145802672205613e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.0007511836327165093, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007511836327165093\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8219330835953905, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8219330835953905\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7497445994709139, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7497445994709139\n",
     "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:20:21,723]\u001b[0m Trial 72 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:22,398]\u001b[0m Trial 73 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:23,116]\u001b[0m Trial 74 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:25,922]\u001b[0m Trial 75 finished with value: 0.28736056697664375 and parameters: {'learning_rate': 0.24525096134080338, 'max_depth': 179, 'lambda_l1': 0.027755681223151637, 'lambda_l2': 2.843448738518365e-06, 'num_leaves': 117, 'n_estimators': 147, 'feature_fraction': 0.6526646029028946, 'bagging_fraction': 0.923901877141479, 'bagging_freq': 1, 'min_child_samples': 52}. Best is trial 37 with value: 0.28531781574642806.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.045084036382109e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.045084036382109e-06\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.006728171209010226, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.006728171209010226\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.4101416981810242, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4101416981810242\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7062858187940941, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7062858187940941\n",
     "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:20:26,576]\u001b[0m Trial 76 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:27,769]\u001b[0m Trial 77 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:28,684]\u001b[0m Trial 78 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:29,419]\u001b[0m Trial 79 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:30,323]\u001b[0m Trial 80 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:33,253]\u001b[0m Trial 81 finished with value: 0.2861566962719253 and parameters: {'learning_rate': 0.24460197732236766, 'max_depth': 179, 'lambda_l1': 0.02872615529175403, 'lambda_l2': 1.3972730439669055e-07, 'num_leaves': 119, 'n_estimators': 565, 'feature_fraction': 0.6487544699833864, 'bagging_fraction': 0.9356835355332597, 'bagging_freq': 1, 'min_child_samples': 51}. Best is trial 37 with value: 0.28531781574642806.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=7.500475394651148e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.500475394651148e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.162054706520921, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.162054706520921\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9763867069564548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9763867069564548\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6271229864421598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6271229864421598\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:20:33,834]\u001b[0m Trial 82 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:36,771]\u001b[0m Trial 83 finished with value: 0.28563344004112784 and parameters: {'learning_rate': 0.31256152594949627, 'max_depth': 296, 'lambda_l1': 0.049396523846069844, 'lambda_l2': 2.6722840445213946e-08, 'num_leaves': 113, 'n_estimators': 831, 'feature_fraction': 0.68208737011263, 'bagging_fraction': 0.9022347017633868, 'bagging_freq': 1, 'min_child_samples': 61}. Best is trial 37 with value: 0.28531781574642806.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.0651941700375071e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0651941700375071e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.05988679767963829, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05988679767963829\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8904832704215764, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8904832704215764\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6837894602566864, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6837894602566864\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:20:37,800]\u001b[0m Trial 84 pruned. Trial was pruned at iteration 22.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:38,755]\u001b[0m Trial 85 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:39,684]\u001b[0m Trial 86 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:40,790]\u001b[0m Trial 87 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:41,893]\u001b[0m Trial 88 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:42,634]\u001b[0m Trial 89 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:43,822]\u001b[0m Trial 90 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:44,517]\u001b[0m Trial 91 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:45,265]\u001b[0m Trial 92 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:46,184]\u001b[0m Trial 93 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:47,061]\u001b[0m Trial 94 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:47,827]\u001b[0m Trial 95 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:48,526]\u001b[0m Trial 96 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:49,235]\u001b[0m Trial 97 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:50,018]\u001b[0m Trial 98 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:50,562]\u001b[0m Trial 99 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:51,249]\u001b[0m Trial 100 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:52,287]\u001b[0m Trial 101 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:52,954]\u001b[0m Trial 102 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:56,382]\u001b[0m Trial 103 finished with value: 0.28512803188594105 and parameters: {'learning_rate': 0.227281777392287, 'max_depth': 183, 'lambda_l1': 0.06184376573655355, 'lambda_l2': 4.725155065027163e-06, 'num_leaves': 105, 'n_estimators': 1920, 'feature_fraction': 0.6202467253412857, 'bagging_fraction': 0.9446155954670866, 'bagging_freq': 1, 'min_child_samples': 48}. Best is trial 103 with value: 0.28512803188594105.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=2.695973546642871e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.695973546642871e-06\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.21637667024601814, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21637667024601814\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9545024681546078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9545024681546078\n",
     "[LightGBM] [Warning] feature_fraction is set=0.5564174603870052, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5564174603870052\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:20:57,094]\u001b[0m Trial 104 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:58,182]\u001b[0m Trial 105 pruned. Trial was pruned at iteration 22.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:58,878]\u001b[0m Trial 106 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:20:59,595]\u001b[0m Trial 107 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:00,741]\u001b[0m Trial 108 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:01,720]\u001b[0m Trial 109 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:02,551]\u001b[0m Trial 110 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:03,579]\u001b[0m Trial 111 pruned. Trial was pruned at iteration 22.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:06,495]\u001b[0m Trial 112 finished with value: 0.2858794012990416 and parameters: {'learning_rate': 0.32336788772920894, 'max_depth': 152, 'lambda_l1': 0.08172382892625016, 'lambda_l2': 4.830122522885557e-06, 'num_leaves': 99, 'n_estimators': 171, 'feature_fraction': 0.6384770526197061, 'bagging_fraction': 0.9065983793460785, 'bagging_freq': 1, 'min_child_samples': 45}. Best is trial 103 with value: 0.28512803188594105.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.688241173482248e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.688241173482248e-06\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.4238949591139642, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4238949591139642\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9093729051324636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9093729051324636\n",
     "[LightGBM] [Warning] feature_fraction is set=0.5772817876045386, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5772817876045386\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:21:07,191]\u001b[0m Trial 113 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:12,697]\u001b[0m Trial 114 finished with value: 0.2856615619050895 and parameters: {'learning_rate': 0.42433604147573234, 'max_depth': 127, 'lambda_l1': 0.08925296109676306, 'lambda_l2': 0.0003525520667240447, 'num_leaves': 100, 'n_estimators': 465, 'feature_fraction': 0.6339771681828874, 'bagging_fraction': 0.452656078823525, 'bagging_freq': 1, 'min_child_samples': 91}. Best is trial 103 with value: 0.28512803188594105.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.0002108576727138622, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002108576727138622\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.08824858019137466, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08824858019137466\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.45657357374673857, subsample=1.0 will be ignored. Current value: bagging_fraction=0.45657357374673857\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6003742957999372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6003742957999372\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:21:13,678]\u001b[0m Trial 115 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:18,045]\u001b[0m Trial 116 finished with value: 0.2860817063467663 and parameters: {'learning_rate': 0.3725738642076954, 'max_depth': 103, 'lambda_l1': 0.05269593425981879, 'lambda_l2': 0.00044556303396341504, 'num_leaves': 109, 'n_estimators': 105, 'feature_fraction': 0.6133422847007463, 'bagging_fraction': 0.41959682131323617, 'bagging_freq': 1, 'min_child_samples': 91}. Best is trial 103 with value: 0.28512803188594105.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.0006207315862663105, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006207315862663105\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.16351387650083155, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16351387650083155\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.42156631083524626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.42156631083524626\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6128691327191046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6128691327191046\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:21:19,031]\u001b[0m Trial 117 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:20,304]\u001b[0m Trial 118 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:21,089]\u001b[0m Trial 119 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:21,963]\u001b[0m Trial 120 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:22,939]\u001b[0m Trial 121 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:24,026]\u001b[0m Trial 122 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:28,872]\u001b[0m Trial 123 finished with value: 0.2862077174552081 and parameters: {'learning_rate': 0.2331718917020949, 'max_depth': 76, 'lambda_l1': 0.02103835840239659, 'lambda_l2': 0.0071748736920341, 'num_leaves': 111, 'n_estimators': 3968, 'feature_fraction': 0.6402865804161346, 'bagging_fraction': 0.4513547423253623, 'bagging_freq': 1, 'min_child_samples': 89}. Best is trial 103 with value: 0.28512803188594105.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.005156471059866587, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005156471059866587\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.01574303932383021, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01574303932383021\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.4497536881551995, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4497536881551995\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6398434981199234, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6398434981199234\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:21:33,300]\u001b[0m Trial 124 finished with value: 0.28641487918078584 and parameters: {'learning_rate': 0.23026494385031743, 'max_depth': 114, 'lambda_l1': 0.01574303932383021, 'lambda_l2': 0.005156471059866587, 'num_leaves': 109, 'n_estimators': 3905, 'feature_fraction': 0.6398434981199234, 'bagging_fraction': 0.4497536881551995, 'bagging_freq': 1, 'min_child_samples': 82}. Best is trial 103 with value: 0.28512803188594105.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.004987564501918241, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004987564501918241\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.022372615809675096, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.022372615809675096\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.41608452501737603, subsample=1.0 will be ignored. Current value: bagging_fraction=0.41608452501737603\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6419128777208665, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6419128777208665\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:21:38,164]\u001b[0m Trial 125 finished with value: 0.286310692607657 and parameters: {'learning_rate': 0.24117033219231815, 'max_depth': 116, 'lambda_l1': 0.022372615809675096, 'lambda_l2': 0.004987564501918241, 'num_leaves': 111, 'n_estimators': 3971, 'feature_fraction': 0.6419128777208665, 'bagging_fraction': 0.41608452501737603, 'bagging_freq': 1, 'min_child_samples': 82}. Best is trial 103 with value: 0.28512803188594105.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.003514818502930925, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003514818502930925\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.7493742276073275, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7493742276073275\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.426160223654815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.426160223654815\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6460794019411868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6460794019411868\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:21:38,814]\u001b[0m Trial 126 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:39,563]\u001b[0m Trial 127 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:43,790]\u001b[0m Trial 128 finished with value: 0.28619005950450715 and parameters: {'learning_rate': 0.2592716101460863, 'max_depth': 119, 'lambda_l1': 0.01802320090186343, 'lambda_l2': 0.006986185128679397, 'num_leaves': 101, 'n_estimators': 3739, 'feature_fraction': 0.6734788129848497, 'bagging_fraction': 0.4160122782797088, 'bagging_freq': 1, 'min_child_samples': 79}. Best is trial 103 with value: 0.28512803188594105.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.005916517352034008, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005916517352034008\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.020830272550022233, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.020830272550022233\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.414681053405901, subsample=1.0 will be ignored. Current value: bagging_fraction=0.414681053405901\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6699468125431582, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6699468125431582\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:21:44,908]\u001b[0m Trial 129 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:45,779]\u001b[0m Trial 130 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:46,942]\u001b[0m Trial 131 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:47,679]\u001b[0m Trial 132 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:54,277]\u001b[0m Trial 133 finished with value: 0.28572778724298903 and parameters: {'learning_rate': 0.3176116838912293, 'max_depth': 62, 'lambda_l1': 0.08591376592832387, 'lambda_l2': 0.004704848780211451, 'num_leaves': 115, 'n_estimators': 3982, 'feature_fraction': 0.6581373604640074, 'bagging_fraction': 0.4811389853093806, 'bagging_freq': 1, 'min_child_samples': 85}. Best is trial 103 with value: 0.28512803188594105.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.004603338347407133, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004603338347407133\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.08195640295968852, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08195640295968852\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.4828062966707858, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4828062966707858\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6622624758291146, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6622624758291146\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:21:55,367]\u001b[0m Trial 134 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:56,317]\u001b[0m Trial 135 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:57,301]\u001b[0m Trial 136 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:58,427]\u001b[0m Trial 137 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:59,341]\u001b[0m Trial 138 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:21:59,946]\u001b[0m Trial 139 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:06,253]\u001b[0m Trial 140 finished with value: 0.2852870373821442 and parameters: {'learning_rate': 0.3081849281405007, 'max_depth': 111, 'lambda_l1': 0.07029752239333421, 'lambda_l2': 0.0035908756809156102, 'num_leaves': 112, 'n_estimators': 3783, 'feature_fraction': 0.6775745030013961, 'bagging_fraction': 0.41788421698267286, 'bagging_freq': 1, 'min_child_samples': 92}. Best is trial 103 with value: 0.28512803188594105.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.0031966949970046203, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0031966949970046203\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.05594224699534066, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05594224699534066\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.4175890208502756, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4175890208502756\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6817969108307101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6817969108307101\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:22:07,412]\u001b[0m Trial 141 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:08,249]\u001b[0m Trial 142 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:09,396]\u001b[0m Trial 143 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:10,111]\u001b[0m Trial 144 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:10,962]\u001b[0m Trial 145 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:11,830]\u001b[0m Trial 146 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:16,590]\u001b[0m Trial 147 finished with value: 0.2862962554660894 and parameters: {'learning_rate': 0.24382456493288673, 'max_depth': 81, 'lambda_l1': 0.014038480271951558, 'lambda_l2': 0.0013702106119546475, 'num_leaves': 133, 'n_estimators': 3999, 'feature_fraction': 0.6526450100366394, 'bagging_fraction': 0.4488403923382832, 'bagging_freq': 1, 'min_child_samples': 80}. Best is trial 103 with value: 0.28512803188594105.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.0015857177475072759, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015857177475072759\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.0070083258282338315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0070083258282338315\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.4764445906258776, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4764445906258776\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6533320448873354, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6533320448873354\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:22:17,611]\u001b[0m Trial 148 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:20,791]\u001b[0m Trial 149 finished with value: 0.28576064663202577 and parameters: {'learning_rate': 0.30649797382592514, 'max_depth': 53, 'lambda_l1': 0.04332495903606048, 'lambda_l2': 0.00017931880865368983, 'num_leaves': 129, 'n_estimators': 582, 'feature_fraction': 0.674411578434018, 'bagging_fraction': 0.9026866618453118, 'bagging_freq': 1, 'min_child_samples': 90}. Best is trial 103 with value: 0.28512803188594105.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.00018583291217839017, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00018583291217839017\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.12813796191839202, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12813796191839202\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8815704358461434, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8815704358461434\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6905678686455825, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6905678686455825\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:22:21,695]\u001b[0m Trial 150 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:24,810]\u001b[0m Trial 151 finished with value: 0.2863302713522494 and parameters: {'learning_rate': 0.2738575468483722, 'max_depth': 52, 'lambda_l1': 0.041282863692067455, 'lambda_l2': 0.013529936093049888, 'num_leaves': 127, 'n_estimators': 435, 'feature_fraction': 0.6710532454830237, 'bagging_fraction': 0.9320497846806391, 'bagging_freq': 1, 'min_child_samples': 95}. Best is trial 103 with value: 0.28512803188594105.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.0026244412564776142, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0026244412564776142\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.025158409450021936, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.025158409450021936\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9049267101421731, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9049267101421731\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6106291117520649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6106291117520649\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:22:25,439]\u001b[0m Trial 152 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:26,352]\u001b[0m Trial 153 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:27,009]\u001b[0m Trial 154 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:27,672]\u001b[0m Trial 155 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:28,609]\u001b[0m Trial 156 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:29,635]\u001b[0m Trial 157 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:30,600]\u001b[0m Trial 158 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:31,540]\u001b[0m Trial 159 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:32,221]\u001b[0m Trial 160 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:33,198]\u001b[0m Trial 161 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:36,224]\u001b[0m Trial 162 finished with value: 0.2863982411569646 and parameters: {'learning_rate': 0.2624044832045877, 'max_depth': 19, 'lambda_l1': 0.033141926327765914, 'lambda_l2': 0.007025592698770755, 'num_leaves': 123, 'n_estimators': 458, 'feature_fraction': 0.6887634825612747, 'bagging_fraction': 0.9207192201714838, 'bagging_freq': 1, 'min_child_samples': 91}. Best is trial 103 with value: 0.28512803188594105.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.02070398547106863, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.02070398547106863\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.08770659800760489, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08770659800760489\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9298038612247789, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9298038612247789\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6667217850806161, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6667217850806161\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:22:40,048]\u001b[0m Trial 163 finished with value: 0.2851116770788378 and parameters: {'learning_rate': 0.30020389632248534, 'max_depth': 55, 'lambda_l1': 0.08770659800760489, 'lambda_l2': 0.02070398547106863, 'num_leaves': 113, 'n_estimators': 518, 'feature_fraction': 0.6667217850806161, 'bagging_fraction': 0.9298038612247789, 'bagging_freq': 1, 'min_child_samples': 95}. Best is trial 163 with value: 0.2851116770788378.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.008970295973861151, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.008970295973861151\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.061907533695101664, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.061907533695101664\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8828139318570859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8828139318570859\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6480742186501642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6480742186501642\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:22:41,014]\u001b[0m Trial 164 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:41,802]\u001b[0m Trial 165 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:42,457]\u001b[0m Trial 166 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:43,320]\u001b[0m Trial 167 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:44,176]\u001b[0m Trial 168 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:44,845]\u001b[0m Trial 169 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:45,567]\u001b[0m Trial 170 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:48,844]\u001b[0m Trial 171 finished with value: 0.2861642191215349 and parameters: {'learning_rate': 0.27039147224964355, 'max_depth': 50, 'lambda_l1': 0.04450536251639491, 'lambda_l2': 0.012291933578380551, 'num_leaves': 129, 'n_estimators': 499, 'feature_fraction': 0.6714701000391127, 'bagging_fraction': 0.9311351852558077, 'bagging_freq': 1, 'min_child_samples': 95}. Best is trial 163 with value: 0.2851116770788378.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.026342584423498756, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.026342584423498756\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.03027827978187911, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03027827978187911\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9314226174760531, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9314226174760531\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6984036206131398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6984036206131398\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:22:51,557]\u001b[0m Trial 172 finished with value: 0.28580649465992725 and parameters: {'learning_rate': 0.28431996531641024, 'max_depth': 32, 'lambda_l1': 0.03027827978187911, 'lambda_l2': 0.026342584423498756, 'num_leaves': 105, 'n_estimators': 498, 'feature_fraction': 0.6984036206131398, 'bagging_fraction': 0.9314226174760531, 'bagging_freq': 1, 'min_child_samples': 94}. Best is trial 163 with value: 0.2851116770788378.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.028037190179256207, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.028037190179256207\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.043820653610012555, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.043820653610012555\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9250292456563854, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9250292456563854\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6952597627604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6952597627604\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:22:54,626]\u001b[0m Trial 173 finished with value: 0.28638859583635357 and parameters: {'learning_rate': 0.2862536127974429, 'max_depth': 11, 'lambda_l1': 0.043820653610012555, 'lambda_l2': 0.028037190179256207, 'num_leaves': 130, 'n_estimators': 483, 'feature_fraction': 0.6952597627604, 'bagging_fraction': 0.9250292456563854, 'bagging_freq': 1, 'min_child_samples': 93}. Best is trial 163 with value: 0.2851116770788378.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.048676160509104796, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.048676160509104796\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.029287548836141233, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.029287548836141233\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9367507205857708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9367507205857708\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7096669428125199, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7096669428125199\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:22:55,596]\u001b[0m Trial 174 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:56,238]\u001b[0m Trial 175 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:56,986]\u001b[0m Trial 176 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:58,072]\u001b[0m Trial 177 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:58,652]\u001b[0m Trial 178 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:22:59,479]\u001b[0m Trial 179 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:03,824]\u001b[0m Trial 180 finished with value: 0.2859886056038321 and parameters: {'learning_rate': 0.29143084657858365, 'max_depth': 20, 'lambda_l1': 0.01489046853235427, 'lambda_l2': 0.00025430171514317056, 'num_leaves': 123, 'n_estimators': 744, 'feature_fraction': 0.6572996134720116, 'bagging_fraction': 0.9612037843558077, 'bagging_freq': 2, 'min_child_samples': 98}. Best is trial 163 with value: 0.2851116770788378.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.00031816457869707974, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00031816457869707974\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.014011446216665495, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.014011446216665495\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9798524914173784, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9798524914173784\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6612577589168523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6612577589168523\n",
     "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:23:04,997]\u001b[0m Trial 181 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:06,088]\u001b[0m Trial 182 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:07,036]\u001b[0m Trial 183 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:10,492]\u001b[0m Trial 184 finished with value: 0.28631923772231666 and parameters: {'learning_rate': 0.3753021357663903, 'max_depth': 32, 'lambda_l1': 0.04518991257924203, 'lambda_l2': 0.00019529350155997747, 'num_leaves': 138, 'n_estimators': 742, 'feature_fraction': 0.6533282142896809, 'bagging_fraction': 0.888995286438531, 'bagging_freq': 1, 'min_child_samples': 93}. Best is trial 163 with value: 0.2851116770788378.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.00026676216650348264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00026676216650348264\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.02177221172955318, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02177221172955318\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9460116688411639, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9460116688411639\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6829616182848973, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6829616182848973\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:23:11,115]\u001b[0m Trial 185 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:12,059]\u001b[0m Trial 186 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:12,964]\u001b[0m Trial 187 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:13,817]\u001b[0m Trial 188 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:14,435]\u001b[0m Trial 189 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:15,083]\u001b[0m Trial 190 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:15,808]\u001b[0m Trial 191 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:16,951]\u001b[0m Trial 192 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:17,912]\u001b[0m Trial 193 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:18,828]\u001b[0m Trial 194 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:19,483]\u001b[0m Trial 195 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:20,364]\u001b[0m Trial 196 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:21,232]\u001b[0m Trial 197 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:21,898]\u001b[0m Trial 198 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:22,541]\u001b[0m Trial 199 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:23,310]\u001b[0m Trial 200 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:24,309]\u001b[0m Trial 201 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:25,297]\u001b[0m Trial 202 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:28,458]\u001b[0m Trial 203 finished with value: 0.28569828794266144 and parameters: {'learning_rate': 0.3188283097494122, 'max_depth': 32, 'lambda_l1': 0.04507914767126509, 'lambda_l2': 0.00036482716537226696, 'num_leaves': 122, 'n_estimators': 1027, 'feature_fraction': 0.6382165512662576, 'bagging_fraction': 0.9316224956836416, 'bagging_freq': 1, 'min_child_samples': 93}. Best is trial 163 with value: 0.2851116770788378.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.0004045333965717266, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0004045333965717266\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.07802565239664884, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07802565239664884\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9318432203922986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9318432203922986\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6299731826026009, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6299731826026009\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:23:29,207]\u001b[0m Trial 204 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:29,927]\u001b[0m Trial 205 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:31,115]\u001b[0m Trial 206 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:32,027]\u001b[0m Trial 207 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:32,896]\u001b[0m Trial 208 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:33,476]\u001b[0m Trial 209 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:37,917]\u001b[0m Trial 210 finished with value: 0.2864599840942761 and parameters: {'learning_rate': 0.24904207342014262, 'max_depth': 75, 'lambda_l1': 0.012385554974598686, 'lambda_l2': 0.005701415634742977, 'num_leaves': 101, 'n_estimators': 950, 'feature_fraction': 0.662479404330411, 'bagging_fraction': 0.43065981143456916, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 163 with value: 0.2851116770788378.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.0002212301534988735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002212301534988735\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.045753189970835655, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.045753189970835655\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8928168016985732, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8928168016985732\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6501098492041978, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6501098492041978\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:23:38,820]\u001b[0m Trial 211 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:39,718]\u001b[0m Trial 212 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:43,722]\u001b[0m Trial 213 finished with value: 0.28576291814307964 and parameters: {'learning_rate': 0.29816665038698953, 'max_depth': 18, 'lambda_l1': 0.07588915489632195, 'lambda_l2': 0.00011581915615510759, 'num_leaves': 155, 'n_estimators': 874, 'feature_fraction': 0.6866684983971157, 'bagging_fraction': 0.9223927678015356, 'bagging_freq': 1, 'min_child_samples': 93}. Best is trial 163 with value: 0.2851116770788378.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=7.604047429640922e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.604047429640922e-05\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.19544737773208506, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19544737773208506\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9380146362517165, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9380146362517165\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6851921896479205, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6851921896479205\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:23:44,372]\u001b[0m Trial 214 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:45,265]\u001b[0m Trial 215 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:46,022]\u001b[0m Trial 216 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:49,153]\u001b[0m Trial 217 finished with value: 0.28605193160896114 and parameters: {'learning_rate': 0.34336938696719976, 'max_depth': 86, 'lambda_l1': 0.07009475732025586, 'lambda_l2': 0.00034386800853440804, 'num_leaves': 105, 'n_estimators': 613, 'feature_fraction': 0.6234832280036762, 'bagging_fraction': 0.9032946177719829, 'bagging_freq': 1, 'min_child_samples': 91}. Best is trial 163 with value: 0.2851116770788378.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.0005737088686884839, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005737088686884839\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.10095730065797592, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10095730065797592\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9047861059368756, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9047861059368756\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6198429442284926, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6198429442284926\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:23:53,649]\u001b[0m Trial 218 finished with value: 0.2854688073738006 and parameters: {'learning_rate': 0.35349137190434954, 'max_depth': 89, 'lambda_l1': 0.10095730065797592, 'lambda_l2': 0.0005737088686884839, 'num_leaves': 158, 'n_estimators': 688, 'feature_fraction': 0.6198429442284926, 'bagging_fraction': 0.9047861059368756, 'bagging_freq': 1, 'min_child_samples': 96}. Best is trial 163 with value: 0.2851116770788378.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.00039640318290560004, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00039640318290560004\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.15042627892913232, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15042627892913232\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9019385060149396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9019385060149396\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6148765977406769, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6148765977406769\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:23:54,362]\u001b[0m Trial 219 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:23:58,807]\u001b[0m Trial 220 finished with value: 0.2852474530414222 and parameters: {'learning_rate': 0.34139748464743, 'max_depth': 476, 'lambda_l1': 0.10960064269448859, 'lambda_l2': 0.0005933873143880924, 'num_leaves': 161, 'n_estimators': 646, 'feature_fraction': 0.6265350363829133, 'bagging_fraction': 0.9172464737620397, 'bagging_freq': 1, 'min_child_samples': 96}. Best is trial 163 with value: 0.2851116770788378.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.00029445135106759236, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00029445135106759236\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.10806951963942268, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10806951963942268\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9149131928745371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9149131928745371\n",
     "[LightGBM] [Warning] feature_fraction is set=0.5951115544794086, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5951115544794086\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:23:59,496]\u001b[0m Trial 221 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:00,354]\u001b[0m Trial 222 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:01,228]\u001b[0m Trial 223 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:01,989]\u001b[0m Trial 224 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:02,896]\u001b[0m Trial 225 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:03,585]\u001b[0m Trial 226 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:08,085]\u001b[0m Trial 227 finished with value: 0.2853698470617397 and parameters: {'learning_rate': 0.38110800786495014, 'max_depth': 404, 'lambda_l1': 0.09427699958735841, 'lambda_l2': 6.060695381517121e-07, 'num_leaves': 164, 'n_estimators': 875, 'feature_fraction': 0.6739668989133856, 'bagging_fraction': 0.9188426906844356, 'bagging_freq': 1, 'min_child_samples': 92}. Best is trial 163 with value: 0.2851116770788378.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.7424629830238606e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7424629830238606e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.16143698659621053, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16143698659621053\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9173261129322943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9173261129322943\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6977037628003883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6977037628003883\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:24:11,738]\u001b[0m Trial 228 finished with value: 0.2852169829768244 and parameters: {'learning_rate': 0.4521028523336675, 'max_depth': 401, 'lambda_l1': 0.16143698659621053, 'lambda_l2': 1.7424629830238606e-07, 'num_leaves': 160, 'n_estimators': 836, 'feature_fraction': 0.6977037628003883, 'bagging_fraction': 0.9173261129322943, 'bagging_freq': 1, 'min_child_samples': 96}. Best is trial 163 with value: 0.2851116770788378.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=2.0167444870740035e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0167444870740035e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.19330101181152706, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19330101181152706\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9207750038685945, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9207750038685945\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7107444078041895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7107444078041895\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:24:15,934]\u001b[0m Trial 229 finished with value: 0.2850843049398256 and parameters: {'learning_rate': 0.48405907342428967, 'max_depth': 412, 'lambda_l1': 0.19330101181152706, 'lambda_l2': 2.0167444870740035e-07, 'num_leaves': 165, 'n_estimators': 940, 'feature_fraction': 0.7107444078041895, 'bagging_fraction': 0.9207750038685945, 'bagging_freq': 1, 'min_child_samples': 97}. Best is trial 229 with value: 0.2850843049398256.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=2.1050870582495692e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.1050870582495692e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.2641208813742509, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2641208813742509\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9139248350613698, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9139248350613698\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7049212595619849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7049212595619849\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:24:16,631]\u001b[0m Trial 230 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:17,277]\u001b[0m Trial 231 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:20,958]\u001b[0m Trial 232 finished with value: 0.28530647985836977 and parameters: {'learning_rate': 0.4801494177600212, 'max_depth': 428, 'lambda_l1': 0.17498261611706675, 'lambda_l2': 1.1839823266358797e-07, 'num_leaves': 161, 'n_estimators': 860, 'feature_fraction': 0.6744906941486014, 'bagging_fraction': 0.9053187442196516, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 229 with value: 0.2850843049398256.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=7.511853708331108e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.511853708331108e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.17466029207526715, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17466029207526715\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9049080853209913, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9049080853209913\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7082727019964934, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7082727019964934\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:24:24,832]\u001b[0m Trial 233 finished with value: 0.2853076348376256 and parameters: {'learning_rate': 0.46792583062312665, 'max_depth': 386, 'lambda_l1': 0.17466029207526715, 'lambda_l2': 7.511853708331108e-08, 'num_leaves': 164, 'n_estimators': 912, 'feature_fraction': 0.7082727019964934, 'bagging_fraction': 0.9049080853209913, 'bagging_freq': 1, 'min_child_samples': 99}. Best is trial 229 with value: 0.2850843049398256.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=7.626431077248298e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.626431077248298e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.42864057594838473, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.42864057594838473\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9011955110845347, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9011955110845347\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7356547795538867, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7356547795538867\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:24:25,507]\u001b[0m Trial 234 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:29,846]\u001b[0m Trial 235 finished with value: 0.2852085088447463 and parameters: {'learning_rate': 0.42764061891854205, 'max_depth': 387, 'lambda_l1': 0.1960214396201557, 'lambda_l2': 1.686394258980281e-07, 'num_leaves': 167, 'n_estimators': 867, 'feature_fraction': 0.7043744023966669, 'bagging_fraction': 0.8869136087879562, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 229 with value: 0.2850843049398256.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.3619018424015203e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.3619018424015203e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.19756374360198983, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19756374360198983\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8689437721631156, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8689437721631156\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7167679829389917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7167679829389917\n",
     "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:24:30,768]\u001b[0m Trial 236 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:34,592]\u001b[0m Trial 237 finished with value: 0.28547997563271166 and parameters: {'learning_rate': 0.4622694714524843, 'max_depth': 393, 'lambda_l1': 0.14532271742034059, 'lambda_l2': 1.969846308066766e-07, 'num_leaves': 179, 'n_estimators': 867, 'feature_fraction': 0.7005086982955494, 'bagging_fraction': 0.8894274872857892, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 229 with value: 0.2850843049398256.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=8.329077355510157e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.329077355510157e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.33098557544517704, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.33098557544517704\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8925829111126569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8925829111126569\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7031789524066666, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7031789524066666\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:24:35,269]\u001b[0m Trial 238 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:36,357]\u001b[0m Trial 239 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:37,423]\u001b[0m Trial 240 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:41,396]\u001b[0m Trial 241 finished with value: 0.2854560783611736 and parameters: {'learning_rate': 0.4062203893443518, 'max_depth': 418, 'lambda_l1': 0.14535968932057525, 'lambda_l2': 1.2362446933206654e-07, 'num_leaves': 165, 'n_estimators': 816, 'feature_fraction': 0.7266740201687704, 'bagging_fraction': 0.9066305042993068, 'bagging_freq': 1, 'min_child_samples': 97}. Best is trial 229 with value: 0.2850843049398256.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.2365624078761626e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2365624078761626e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.22213395367412836, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22213395367412836\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8888340280890189, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8888340280890189\n",
     "[LightGBM] [Warning] feature_fraction is set=0.729181475454753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.729181475454753\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:24:42,188]\u001b[0m Trial 242 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:46,286]\u001b[0m Trial 243 finished with value: 0.2849040072846442 and parameters: {'learning_rate': 0.4032789693459414, 'max_depth': 386, 'lambda_l1': 0.14130606123893438, 'lambda_l2': 2.0916356464116602e-07, 'num_leaves': 176, 'n_estimators': 994, 'feature_fraction': 0.7048136599322551, 'bagging_fraction': 0.9148527373387274, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=5.390137226075619e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.390137226075619e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.15810925759268127, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15810925759268127\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.91282481084142, subsample=1.0 will be ignored. Current value: bagging_fraction=0.91282481084142\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7068409623073482, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7068409623073482\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:24:50,349]\u001b[0m Trial 244 finished with value: 0.28500572299678617 and parameters: {'learning_rate': 0.4058824199524637, 'max_depth': 387, 'lambda_l1': 0.15810925759268127, 'lambda_l2': 5.390137226075619e-08, 'num_leaves': 179, 'n_estimators': 996, 'feature_fraction': 0.7068409623073482, 'bagging_fraction': 0.91282481084142, 'bagging_freq': 1, 'min_child_samples': 97}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=5.334603272651986e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.334603272651986e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.1379793825910051, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1379793825910051\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9067314353300775, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9067314353300775\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7211999210015401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7211999210015401\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:24:54,418]\u001b[0m Trial 245 pruned. Trial was pruned at iteration 155.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:55,114]\u001b[0m Trial 246 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:55,967]\u001b[0m Trial 247 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:56,706]\u001b[0m Trial 248 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:57,934]\u001b[0m Trial 249 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:58,575]\u001b[0m Trial 250 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:24:59,439]\u001b[0m Trial 251 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:03,745]\u001b[0m Trial 252 finished with value: 0.2855961177708826 and parameters: {'learning_rate': 0.45090180186686407, 'max_depth': 403, 'lambda_l1': 0.10921630271889797, 'lambda_l2': 1.2638146605574543e-07, 'num_leaves': 181, 'n_estimators': 863, 'feature_fraction': 0.7062557648696228, 'bagging_fraction': 0.9117620463286707, 'bagging_freq': 1, 'min_child_samples': 97}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.3737753243328266e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.3737753243328266e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.25924548860161617, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.25924548860161617\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9175748803118519, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9175748803118519\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7204186669882802, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7204186669882802\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:25:04,462]\u001b[0m Trial 253 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:09,192]\u001b[0m Trial 254 finished with value: 0.2853727174702844 and parameters: {'learning_rate': 0.38946686496289584, 'max_depth': 381, 'lambda_l1': 0.11502773510223588, 'lambda_l2': 6.336130669696578e-08, 'num_leaves': 191, 'n_estimators': 973, 'feature_fraction': 0.7070390418994672, 'bagging_fraction': 0.9221689227486214, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=6.081755610020954e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.081755610020954e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.11611034834318093, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11611034834318093\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9196471900523862, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9196471900523862\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7107323095743826, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7107323095743826\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:25:13,195]\u001b[0m Trial 255 finished with value: 0.28553033496703834 and parameters: {'learning_rate': 0.3889691922908166, 'max_depth': 375, 'lambda_l1': 0.11611034834318093, 'lambda_l2': 6.081755610020954e-08, 'num_leaves': 188, 'n_estimators': 981, 'feature_fraction': 0.7107323095743826, 'bagging_fraction': 0.9196471900523862, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=6.906165886500403e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.906165886500403e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.13878384264008783, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13878384264008783\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8964035211945941, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8964035211945941\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7451350187940384, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7451350187940384\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:25:17,150]\u001b[0m Trial 256 finished with value: 0.2854725646711681 and parameters: {'learning_rate': 0.39568784099690274, 'max_depth': 384, 'lambda_l1': 0.13878384264008783, 'lambda_l2': 6.906165886500403e-08, 'num_leaves': 190, 'n_estimators': 990, 'feature_fraction': 0.7451350187940384, 'bagging_fraction': 0.8964035211945941, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=7.436855812037219e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.436855812037219e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.16299339375575814, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16299339375575814\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8819936862684808, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8819936862684808\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7362445570064772, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7362445570064772\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:25:18,119]\u001b[0m Trial 257 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:19,109]\u001b[0m Trial 258 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:19,892]\u001b[0m Trial 259 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:24,354]\u001b[0m Trial 260 finished with value: 0.28536079599924297 and parameters: {'learning_rate': 0.4379301479873737, 'max_depth': 409, 'lambda_l1': 0.117758617758911, 'lambda_l2': 2.6151095842977927e-08, 'num_leaves': 181, 'n_estimators': 1097, 'feature_fraction': 0.7206581364555009, 'bagging_fraction': 0.9027860534513278, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.4340883329679474e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4340883329679474e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.1281695483256515, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1281695483256515\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9015831988631351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9015831988631351\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7261423797431835, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7261423797431835\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:25:25,379]\u001b[0m Trial 261 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:26,005]\u001b[0m Trial 262 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:26,901]\u001b[0m Trial 263 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:27,621]\u001b[0m Trial 264 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:28,279]\u001b[0m Trial 265 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:28,981]\u001b[0m Trial 266 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:33,257]\u001b[0m Trial 267 finished with value: 0.28547261353609066 and parameters: {'learning_rate': 0.43912311886517735, 'max_depth': 415, 'lambda_l1': 0.12041747370516136, 'lambda_l2': 5.9128832334196173e-08, 'num_leaves': 174, 'n_estimators': 899, 'feature_fraction': 0.7318122807137911, 'bagging_fraction': 0.9176598563374009, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=5.250242307231937e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.250242307231937e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.1229968766279127, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1229968766279127\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8590300522461183, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8590300522461183\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7484726028748652, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7484726028748652\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:25:34,183]\u001b[0m Trial 268 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:34,900]\u001b[0m Trial 269 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:38,583]\u001b[0m Trial 270 finished with value: 0.2851728913103773 and parameters: {'learning_rate': 0.4996383215542074, 'max_depth': 409, 'lambda_l1': 0.17155775200792292, 'lambda_l2': 2.1878079446703054e-07, 'num_leaves': 164, 'n_estimators': 880, 'feature_fraction': 0.7134720750918611, 'bagging_fraction': 0.9110541895599729, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=3.682742706905555e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.682742706905555e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.1826468375627793, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1826468375627793\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9099984906464842, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9099984906464842\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7123411794616724, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7123411794616724\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:25:42,268]\u001b[0m Trial 271 finished with value: 0.28571488279495827 and parameters: {'learning_rate': 0.49779918206222357, 'max_depth': 407, 'lambda_l1': 0.1826468375627793, 'lambda_l2': 3.682742706905555e-07, 'num_leaves': 165, 'n_estimators': 840, 'feature_fraction': 0.7123411794616724, 'bagging_fraction': 0.9099984906464842, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.8418721590579858e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8418721590579858e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.715875600067567, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.715875600067567\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8946975764426516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8946975764426516\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7386621125902038, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7386621125902038\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:25:42,885]\u001b[0m Trial 272 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:46,971]\u001b[0m Trial 273 pruned. Trial was pruned at iteration 168.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:47,630]\u001b[0m Trial 274 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:48,625]\u001b[0m Trial 275 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:49,366]\u001b[0m Trial 276 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:50,169]\u001b[0m Trial 277 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:54,340]\u001b[0m Trial 278 finished with value: 0.2856634094272277 and parameters: {'learning_rate': 0.4231757240040105, 'max_depth': 350, 'lambda_l1': 0.09597385144115726, 'lambda_l2': 1.304967625223134e-07, 'num_leaves': 157, 'n_estimators': 778, 'feature_fraction': 0.6904773643742266, 'bagging_fraction': 0.936670064906779, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=2.1402704289677113e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.1402704289677113e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.3156572632272125, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3156572632272125\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9038914736829832, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9038914736829832\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7302759200372982, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7302759200372982\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:25:55,029]\u001b[0m Trial 279 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:55,777]\u001b[0m Trial 280 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:25:56,370]\u001b[0m Trial 281 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:00,856]\u001b[0m Trial 282 finished with value: 0.28537159787613375 and parameters: {'learning_rate': 0.3614908797322293, 'max_depth': 381, 'lambda_l1': 0.10677939135239561, 'lambda_l2': 3.570683204390966e-08, 'num_leaves': 177, 'n_estimators': 1099, 'feature_fraction': 0.7550713605094026, 'bagging_fraction': 0.9074203784434246, 'bagging_freq': 1, 'min_child_samples': 95}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=3.9342808597393606e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9342808597393606e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.12274400886988186, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12274400886988186\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9184193681569938, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9184193681569938\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7582839328045529, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7582839328045529\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:26:05,301]\u001b[0m Trial 283 finished with value: 0.2853059092876788 and parameters: {'learning_rate': 0.36216954687622893, 'max_depth': 367, 'lambda_l1': 0.12274400886988186, 'lambda_l2': 3.9342808597393606e-08, 'num_leaves': 177, 'n_estimators': 1052, 'feature_fraction': 0.7582839328045529, 'bagging_fraction': 0.9184193681569938, 'bagging_freq': 1, 'min_child_samples': 95}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=3.877079947233658e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.877079947233658e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.12557785396134294, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12557785396134294\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9186957636378781, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9186957636378781\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7566198049408458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7566198049408458\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:26:09,803]\u001b[0m Trial 284 finished with value: 0.2852184984540954 and parameters: {'learning_rate': 0.36871001303878737, 'max_depth': 369, 'lambda_l1': 0.12557785396134294, 'lambda_l2': 3.877079947233658e-08, 'num_leaves': 178, 'n_estimators': 1158, 'feature_fraction': 0.7566198049408458, 'bagging_fraction': 0.9186957636378781, 'bagging_freq': 1, 'min_child_samples': 95}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=3.9784446514804104e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9784446514804104e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.15921974018307003, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15921974018307003\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.940269672183813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.940269672183813\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7562243641136691, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7562243641136691\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:26:10,697]\u001b[0m Trial 285 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:11,359]\u001b[0m Trial 286 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:15,637]\u001b[0m Trial 287 finished with value: 0.28581422990094457 and parameters: {'learning_rate': 0.3934354436445921, 'max_depth': 369, 'lambda_l1': 0.12214189611374977, 'lambda_l2': 5.787147930443188e-08, 'num_leaves': 170, 'n_estimators': 1256, 'feature_fraction': 0.7496502350294421, 'bagging_fraction': 0.9220537934813446, 'bagging_freq': 1, 'min_child_samples': 94}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=2.6718800925721846e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.6718800925721846e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.19569181913081019, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19569181913081019\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9331353226315743, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9331353226315743\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7346232124488152, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7346232124488152\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:26:16,420]\u001b[0m Trial 288 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:17,091]\u001b[0m Trial 289 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:21,219]\u001b[0m Trial 290 finished with value: 0.2860010988538534 and parameters: {'learning_rate': 0.3647090636388819, 'max_depth': 376, 'lambda_l1': 0.07706273637814524, 'lambda_l2': 3.8947509545760287e-08, 'num_leaves': 172, 'n_estimators': 995, 'feature_fraction': 0.7669655654202728, 'bagging_fraction': 0.9125982175969867, 'bagging_freq': 1, 'min_child_samples': 95}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=7.076770802650595e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.076770802650595e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.12517291740535505, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12517291740535505\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9499160668726149, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499160668726149\n",
     "[LightGBM] [Warning] feature_fraction is set=0.774976354826134, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.774976354826134\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:26:22,203]\u001b[0m Trial 291 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:22,906]\u001b[0m Trial 292 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:23,944]\u001b[0m Trial 293 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:24,847]\u001b[0m Trial 294 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:25,605]\u001b[0m Trial 295 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:26,698]\u001b[0m Trial 296 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:27,827]\u001b[0m Trial 297 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:28,578]\u001b[0m Trial 298 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:29,227]\u001b[0m Trial 299 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:33,379]\u001b[0m Trial 300 finished with value: 0.28552939900302526 and parameters: {'learning_rate': 0.3526616661361945, 'max_depth': 370, 'lambda_l1': 0.10503456740222981, 'lambda_l2': 1.635954064041392e-08, 'num_leaves': 155, 'n_estimators': 1194, 'feature_fraction': 0.7335892678482906, 'bagging_fraction': 0.9394500699748406, 'bagging_freq': 1, 'min_child_samples': 96}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.4529091607597528e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4529091607597528e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.07857761351959591, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07857761351959591\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9323508669855193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9323508669855193\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7620180807525583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7620180807525583\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:26:37,205]\u001b[0m Trial 301 finished with value: 0.28578398589108883 and parameters: {'learning_rate': 0.346407744308252, 'max_depth': 390, 'lambda_l1': 0.07857761351959591, 'lambda_l2': 1.4529091607597528e-08, 'num_leaves': 154, 'n_estimators': 1275, 'feature_fraction': 0.7620180807525583, 'bagging_fraction': 0.9323508669855193, 'bagging_freq': 1, 'min_child_samples': 93}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=2.277654132180243e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.277654132180243e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.25661475982506116, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.25661475982506116\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.947796332163954, subsample=1.0 will be ignored. Current value: bagging_fraction=0.947796332163954\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7362483973133763, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7362483973133763\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:26:38,072]\u001b[0m Trial 302 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:42,371]\u001b[0m Trial 303 finished with value: 0.28498429328671604 and parameters: {'learning_rate': 0.3485008653614302, 'max_depth': 463, 'lambda_l1': 0.16248328651184538, 'lambda_l2': 4.445672243526642e-07, 'num_leaves': 162, 'n_estimators': 1211, 'feature_fraction': 0.7439732529349579, 'bagging_fraction': 0.8811475642248596, 'bagging_freq': 1, 'min_child_samples': 96}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=5.909127799727878e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.909127799727878e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.170803870676162, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.170803870676162\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8758810239286929, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8758810239286929\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7501520924515083, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7501520924515083\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:26:43,311]\u001b[0m Trial 304 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:43,998]\u001b[0m Trial 305 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:44,993]\u001b[0m Trial 306 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:45,609]\u001b[0m Trial 307 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:46,648]\u001b[0m Trial 308 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:47,277]\u001b[0m Trial 309 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:48,244]\u001b[0m Trial 310 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:49,224]\u001b[0m Trial 311 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:50,153]\u001b[0m Trial 312 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:50,824]\u001b[0m Trial 313 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:51,836]\u001b[0m Trial 314 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:52,499]\u001b[0m Trial 315 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:53,452]\u001b[0m Trial 316 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:54,494]\u001b[0m Trial 317 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:55,508]\u001b[0m Trial 318 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:26:59,996]\u001b[0m Trial 319 finished with value: 0.2855951282660909 and parameters: {'learning_rate': 0.34024077396386426, 'max_depth': 498, 'lambda_l1': 0.10282510960722557, 'lambda_l2': 1.8027970486520748e-07, 'num_leaves': 166, 'n_estimators': 1240, 'feature_fraction': 0.6998514165450017, 'bagging_fraction': 0.9094011034194582, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=7.512467496670074e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.512467496670074e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.3169864907406054, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3169864907406054\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9308920113192987, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9308920113192987\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7426794393065097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7426794393065097\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:27:00,677]\u001b[0m Trial 320 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:01,293]\u001b[0m Trial 321 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:02,255]\u001b[0m Trial 322 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:02,890]\u001b[0m Trial 323 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:03,939]\u001b[0m Trial 324 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:08,515]\u001b[0m Trial 325 finished with value: 0.2854817337937833 and parameters: {'learning_rate': 0.41357552998369185, 'max_depth': 389, 'lambda_l1': 0.101615599584233, 'lambda_l2': 3.284127507564006e-07, 'num_leaves': 193, 'n_estimators': 1908, 'feature_fraction': 0.756915794043745, 'bagging_fraction': 0.9266805626416965, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=7.588055569684288e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.588055569684288e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.22205545990989825, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22205545990989825\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9177351604680823, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9177351604680823\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7021286924858977, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7021286924858977\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:27:09,140]\u001b[0m Trial 326 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:09,825]\u001b[0m Trial 327 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:10,402]\u001b[0m Trial 328 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:11,456]\u001b[0m Trial 329 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:15,337]\u001b[0m Trial 330 finished with value: 0.28544848226880254 and parameters: {'learning_rate': 0.49550019597644285, 'max_depth': 363, 'lambda_l1': 0.1520645392863425, 'lambda_l2': 2.5770621570746555e-06, 'num_leaves': 165, 'n_estimators': 1053, 'feature_fraction': 0.6945295545560448, 'bagging_fraction': 0.9169987924375648, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.3975279773804795e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.3975279773804795e-06\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.1755693052747138, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1755693052747138\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9361725647159189, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9361725647159189\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7337658777512227, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7337658777512227\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:27:16,168]\u001b[0m Trial 331 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:17,177]\u001b[0m Trial 332 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:17,922]\u001b[0m Trial 333 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:21,739]\u001b[0m Trial 334 finished with value: 0.28581043851800747 and parameters: {'learning_rate': 0.3322019229655581, 'max_depth': 489, 'lambda_l1': 0.057930286455555646, 'lambda_l2': 2.1201596218308627e-06, 'num_leaves': 168, 'n_estimators': 978, 'feature_fraction': 0.748036496408023, 'bagging_fraction': 0.9377346005939219, 'bagging_freq': 1, 'min_child_samples': 96}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=5.763046625125429e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.763046625125429e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.12157905233148893, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12157905233148893\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9224971813927131, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9224971813927131\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7237144981037118, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7237144981037118\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:27:22,736]\u001b[0m Trial 335 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:23,430]\u001b[0m Trial 336 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:24,578]\u001b[0m Trial 337 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:25,514]\u001b[0m Trial 338 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:26,147]\u001b[0m Trial 339 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:26,802]\u001b[0m Trial 340 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:27,981]\u001b[0m Trial 341 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:29,125]\u001b[0m Trial 342 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:29,763]\u001b[0m Trial 343 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:30,771]\u001b[0m Trial 344 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:31,438]\u001b[0m Trial 345 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:32,469]\u001b[0m Trial 346 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:33,142]\u001b[0m Trial 347 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:34,013]\u001b[0m Trial 348 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:34,734]\u001b[0m Trial 349 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:35,382]\u001b[0m Trial 350 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:36,827]\u001b[0m Trial 351 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:37,544]\u001b[0m Trial 352 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:42,224]\u001b[0m Trial 353 finished with value: 0.2853791514386664 and parameters: {'learning_rate': 0.3302645753886701, 'max_depth': 385, 'lambda_l1': 0.10796388964919713, 'lambda_l2': 2.4921356066788732e-06, 'num_leaves': 183, 'n_estimators': 1105, 'feature_fraction': 0.7656172158169238, 'bagging_fraction': 0.9276319621645871, 'bagging_freq': 1, 'min_child_samples': 94}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=3.992446423221995e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.992446423221995e-06\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.09061365942332893, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09061365942332893\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9326905202679545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9326905202679545\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7953091142250813, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953091142250813\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:27:43,196]\u001b[0m Trial 354 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:43,829]\u001b[0m Trial 355 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:44,882]\u001b[0m Trial 356 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:45,493]\u001b[0m Trial 357 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:49,785]\u001b[0m Trial 358 finished with value: 0.2852592414563754 and parameters: {'learning_rate': 0.37770021676057997, 'max_depth': 378, 'lambda_l1': 0.1315775543012027, 'lambda_l2': 1.5213747931344276e-06, 'num_leaves': 147, 'n_estimators': 2478, 'feature_fraction': 0.7793251022124114, 'bagging_fraction': 0.9212808751111013, 'bagging_freq': 1, 'min_child_samples': 92}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=2.701418094046027e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.701418094046027e-06\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.07606865622403149, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07606865622403149\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9264389786133603, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9264389786133603\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7837828478001266, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7837828478001266\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:27:50,432]\u001b[0m Trial 359 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:51,332]\u001b[0m Trial 360 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:51,938]\u001b[0m Trial 361 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:52,638]\u001b[0m Trial 362 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:53,291]\u001b[0m Trial 363 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:53,931]\u001b[0m Trial 364 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:54,863]\u001b[0m Trial 365 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:27:58,912]\u001b[0m Trial 366 finished with value: 0.2858115429578009 and parameters: {'learning_rate': 0.4582753538482233, 'max_depth': 354, 'lambda_l1': 0.1325246438595538, 'lambda_l2': 1.824079506303707e-06, 'num_leaves': 162, 'n_estimators': 1005, 'feature_fraction': 0.796914226806584, 'bagging_fraction': 0.924832486464456, 'bagging_freq': 1, 'min_child_samples': 94}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.4315519809594237e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4315519809594237e-06\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.19486482721082526, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19486482721082526\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9059090160453364, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9059090160453364\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7026948980574603, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7026948980574603\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:27:59,619]\u001b[0m Trial 367 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:00,455]\u001b[0m Trial 368 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:01,857]\u001b[0m Trial 369 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:02,485]\u001b[0m Trial 370 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:06,418]\u001b[0m Trial 371 finished with value: 0.28548337350778535 and parameters: {'learning_rate': 0.4617851458331907, 'max_depth': 380, 'lambda_l1': 0.14200732297279067, 'lambda_l2': 2.4578149986554303e-06, 'num_leaves': 156, 'n_estimators': 950, 'feature_fraction': 0.7635404640035477, 'bagging_fraction': 0.9119278188347857, 'bagging_freq': 1, 'min_child_samples': 92}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.1892460928229899e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1892460928229899e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.08549604549650255, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08549604549650255\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9311046819928209, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9311046819928209\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6904317538645601, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6904317538645601\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:28:10,713]\u001b[0m Trial 372 finished with value: 0.28548303500565136 and parameters: {'learning_rate': 0.3449977454802816, 'max_depth': 274, 'lambda_l1': 0.08549604549650255, 'lambda_l2': 1.1892460928229899e-08, 'num_leaves': 164, 'n_estimators': 3330, 'feature_fraction': 0.6904317538645601, 'bagging_fraction': 0.9311046819928209, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=3.456320642798248e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.456320642798248e-06\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.3119014957412596, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3119014957412596\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9047922659165512, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9047922659165512\n",
     "[LightGBM] [Warning] feature_fraction is set=0.4275108960527536, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4275108960527536\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:28:11,301]\u001b[0m Trial 373 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:12,317]\u001b[0m Trial 374 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:12,966]\u001b[0m Trial 375 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:13,970]\u001b[0m Trial 376 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:14,627]\u001b[0m Trial 377 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:15,285]\u001b[0m Trial 378 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:16,603]\u001b[0m Trial 379 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:17,261]\u001b[0m Trial 380 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:17,939]\u001b[0m Trial 381 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:18,903]\u001b[0m Trial 382 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:23,304]\u001b[0m Trial 383 finished with value: 0.28539021776540624 and parameters: {'learning_rate': 0.3257156582877067, 'max_depth': 352, 'lambda_l1': 0.08067243178287507, 'lambda_l2': 1.4322856696962433e-06, 'num_leaves': 172, 'n_estimators': 919, 'feature_fraction': 0.728178053506652, 'bagging_fraction': 0.9207034127884193, 'bagging_freq': 1, 'min_child_samples': 88}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=2.227531950121127e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.227531950121127e-06\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.04225384637132534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04225384637132534\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9276115450452823, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9276115450452823\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7277893175209662, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7277893175209662\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:28:23,979]\u001b[0m Trial 384 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:24,672]\u001b[0m Trial 385 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:25,531]\u001b[0m Trial 386 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:26,159]\u001b[0m Trial 387 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:27,185]\u001b[0m Trial 388 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:27,904]\u001b[0m Trial 389 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:28,675]\u001b[0m Trial 390 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:29,317]\u001b[0m Trial 391 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:29,987]\u001b[0m Trial 392 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:30,693]\u001b[0m Trial 393 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:31,322]\u001b[0m Trial 394 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:31,998]\u001b[0m Trial 395 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:32,943]\u001b[0m Trial 396 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:33,865]\u001b[0m Trial 397 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:34,519]\u001b[0m Trial 398 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:35,485]\u001b[0m Trial 399 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:36,133]\u001b[0m Trial 400 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:36,786]\u001b[0m Trial 401 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:37,452]\u001b[0m Trial 402 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:38,282]\u001b[0m Trial 403 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:38,978]\u001b[0m Trial 404 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:39,669]\u001b[0m Trial 405 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:44,487]\u001b[0m Trial 406 finished with value: 0.28538227594471266 and parameters: {'learning_rate': 0.3523966895435826, 'max_depth': 376, 'lambda_l1': 0.10924141704619243, 'lambda_l2': 2.50157656607557e-06, 'num_leaves': 163, 'n_estimators': 1258, 'feature_fraction': 0.7263112466409744, 'bagging_fraction': 0.8938135186317775, 'bagging_freq': 1, 'min_child_samples': 87}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=5.896578706920737e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.896578706920737e-06\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.039937111800710176, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.039937111800710176\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8298976393139186, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8298976393139186\n",
     "[LightGBM] [Warning] feature_fraction is set=0.692062875893839, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.692062875893839\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:28:45,133]\u001b[0m Trial 407 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:45,800]\u001b[0m Trial 408 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:50,256]\u001b[0m Trial 409 finished with value: 0.28553438508624257 and parameters: {'learning_rate': 0.33245104319943813, 'max_depth': 378, 'lambda_l1': 0.10946405471086397, 'lambda_l2': 2.1217663851151864e-06, 'num_leaves': 150, 'n_estimators': 1211, 'feature_fraction': 0.743148193791704, 'bagging_fraction': 0.8698694263459652, 'bagging_freq': 1, 'min_child_samples': 89}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=3.7765840662960147e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.7765840662960147e-06\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.0676308444066573, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0676308444066573\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8988442518537461, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8988442518537461\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6658459943733921, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6658459943733921\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:28:51,293]\u001b[0m Trial 410 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:51,942]\u001b[0m Trial 411 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:52,690]\u001b[0m Trial 412 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:53,420]\u001b[0m Trial 413 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:54,324]\u001b[0m Trial 414 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:54,953]\u001b[0m Trial 415 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:55,609]\u001b[0m Trial 416 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:56,601]\u001b[0m Trial 417 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:57,219]\u001b[0m Trial 418 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:57,938]\u001b[0m Trial 419 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:58,911]\u001b[0m Trial 420 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:28:59,624]\u001b[0m Trial 421 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:00,267]\u001b[0m Trial 422 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:01,313]\u001b[0m Trial 423 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:01,943]\u001b[0m Trial 424 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:02,596]\u001b[0m Trial 425 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:03,705]\u001b[0m Trial 426 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:04,298]\u001b[0m Trial 427 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:04,977]\u001b[0m Trial 428 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:05,859]\u001b[0m Trial 429 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:06,553]\u001b[0m Trial 430 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:07,206]\u001b[0m Trial 431 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:08,382]\u001b[0m Trial 432 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:09,009]\u001b[0m Trial 433 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:09,706]\u001b[0m Trial 434 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:10,339]\u001b[0m Trial 435 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:11,102]\u001b[0m Trial 436 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:12,081]\u001b[0m Trial 437 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:12,794]\u001b[0m Trial 438 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:13,680]\u001b[0m Trial 439 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:14,355]\u001b[0m Trial 440 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:15,020]\u001b[0m Trial 441 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:15,655]\u001b[0m Trial 442 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:16,505]\u001b[0m Trial 443 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:17,455]\u001b[0m Trial 444 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:18,564]\u001b[0m Trial 445 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:19,256]\u001b[0m Trial 446 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:19,903]\u001b[0m Trial 447 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:20,578]\u001b[0m Trial 448 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:21,175]\u001b[0m Trial 449 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:22,086]\u001b[0m Trial 450 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:22,839]\u001b[0m Trial 451 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:23,480]\u001b[0m Trial 452 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:24,153]\u001b[0m Trial 453 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:24,875]\u001b[0m Trial 454 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:25,833]\u001b[0m Trial 455 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:27,059]\u001b[0m Trial 456 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:27,816]\u001b[0m Trial 457 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:28,452]\u001b[0m Trial 458 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:29,155]\u001b[0m Trial 459 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:30,183]\u001b[0m Trial 460 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:31,134]\u001b[0m Trial 461 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:32,057]\u001b[0m Trial 462 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:32,732]\u001b[0m Trial 463 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:33,430]\u001b[0m Trial 464 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:34,084]\u001b[0m Trial 465 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:34,696]\u001b[0m Trial 466 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:35,351]\u001b[0m Trial 467 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:36,120]\u001b[0m Trial 468 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:37,189]\u001b[0m Trial 469 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:37,939]\u001b[0m Trial 470 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:42,627]\u001b[0m Trial 471 finished with value: 0.2851105586477252 and parameters: {'learning_rate': 0.3721975511787462, 'max_depth': 383, 'lambda_l1': 0.10665633648149397, 'lambda_l2': 1.4297442381347278e-06, 'num_leaves': 181, 'n_estimators': 942, 'feature_fraction': 0.7795020245784667, 'bagging_fraction': 0.9488508686320927, 'bagging_freq': 1, 'min_child_samples': 86}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=8.546072741386333e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.546072741386333e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.08671211763364325, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08671211763364325\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9593356392288396, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9593356392288396\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7976856078260169, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7976856078260169\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:29:43,276]\u001b[0m Trial 472 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:44,309]\u001b[0m Trial 473 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:45,489]\u001b[0m Trial 474 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:46,158]\u001b[0m Trial 475 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:47,241]\u001b[0m Trial 476 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:48,542]\u001b[0m Trial 477 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:49,336]\u001b[0m Trial 478 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:50,055]\u001b[0m Trial 479 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:50,738]\u001b[0m Trial 480 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:51,757]\u001b[0m Trial 481 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:52,441]\u001b[0m Trial 482 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:53,683]\u001b[0m Trial 483 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:54,617]\u001b[0m Trial 484 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:55,392]\u001b[0m Trial 485 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:56,025]\u001b[0m Trial 486 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:56,747]\u001b[0m Trial 487 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:57,418]\u001b[0m Trial 488 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:58,126]\u001b[0m Trial 489 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:59,090]\u001b[0m Trial 490 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:29:59,763]\u001b[0m Trial 491 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:00,467]\u001b[0m Trial 492 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:01,111]\u001b[0m Trial 493 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:02,426]\u001b[0m Trial 494 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:03,120]\u001b[0m Trial 495 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:04,011]\u001b[0m Trial 496 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:04,698]\u001b[0m Trial 497 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:05,413]\u001b[0m Trial 498 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:06,395]\u001b[0m Trial 499 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:07,073]\u001b[0m Trial 500 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:07,748]\u001b[0m Trial 501 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:08,380]\u001b[0m Trial 502 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:09,080]\u001b[0m Trial 503 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:09,819]\u001b[0m Trial 504 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:10,472]\u001b[0m Trial 505 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:11,337]\u001b[0m Trial 506 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:12,233]\u001b[0m Trial 507 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:12,869]\u001b[0m Trial 508 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:13,521]\u001b[0m Trial 509 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:14,285]\u001b[0m Trial 510 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:15,296]\u001b[0m Trial 511 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:16,192]\u001b[0m Trial 512 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:16,826]\u001b[0m Trial 513 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:17,494]\u001b[0m Trial 514 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:18,303]\u001b[0m Trial 515 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:19,116]\u001b[0m Trial 516 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:20,030]\u001b[0m Trial 517 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:23,529]\u001b[0m Trial 518 finished with value: 0.28561533643875797 and parameters: {'learning_rate': 0.3852548704472848, 'max_depth': 321, 'lambda_l1': 0.12560450759078914, 'lambda_l2': 1.1695294831339238e-06, 'num_leaves': 102, 'n_estimators': 961, 'feature_fraction': 0.7330270030118489, 'bagging_fraction': 0.8918047927714073, 'bagging_freq': 1, 'min_child_samples': 94}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=2.3210749435247432e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3210749435247432e-06\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.24992860845872045, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.24992860845872045\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.910412297918672, subsample=1.0 will be ignored. Current value: bagging_fraction=0.910412297918672\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7030419109000047, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7030419109000047\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:30:24,150]\u001b[0m Trial 519 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:24,991]\u001b[0m Trial 520 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:25,675]\u001b[0m Trial 521 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:26,380]\u001b[0m Trial 522 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:26,995]\u001b[0m Trial 523 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:27,811]\u001b[0m Trial 524 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:28,524]\u001b[0m Trial 525 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:29,157]\u001b[0m Trial 526 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:29,875]\u001b[0m Trial 527 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:30,723]\u001b[0m Trial 528 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:31,388]\u001b[0m Trial 529 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:32,076]\u001b[0m Trial 530 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:32,706]\u001b[0m Trial 531 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:33,352]\u001b[0m Trial 532 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:34,297]\u001b[0m Trial 533 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:35,100]\u001b[0m Trial 534 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:36,212]\u001b[0m Trial 535 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:36,873]\u001b[0m Trial 536 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:37,862]\u001b[0m Trial 537 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:38,499]\u001b[0m Trial 538 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:39,149]\u001b[0m Trial 539 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:40,191]\u001b[0m Trial 540 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:43,835]\u001b[0m Trial 541 finished with value: 0.2856257622796934 and parameters: {'learning_rate': 0.46077226896819273, 'max_depth': 500, 'lambda_l1': 0.10325063578858905, 'lambda_l2': 7.931140333505388e-08, 'num_leaves': 118, 'n_estimators': 926, 'feature_fraction': 0.6913168140872084, 'bagging_fraction': 0.9070736787335929, 'bagging_freq': 1, 'min_child_samples': 86}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.838721386954182e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.838721386954182e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.00035052616522025527, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00035052616522025527\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9308190746737818, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9308190746737818\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6610364712748112, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6610364712748112\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:30:44,463]\u001b[0m Trial 542 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:45,106]\u001b[0m Trial 543 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:45,999]\u001b[0m Trial 544 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:46,745]\u001b[0m Trial 545 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:47,950]\u001b[0m Trial 546 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:48,613]\u001b[0m Trial 547 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:49,280]\u001b[0m Trial 548 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:49,934]\u001b[0m Trial 549 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:50,672]\u001b[0m Trial 550 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:51,382]\u001b[0m Trial 551 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:52,601]\u001b[0m Trial 552 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:53,277]\u001b[0m Trial 553 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:54,487]\u001b[0m Trial 554 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:55,136]\u001b[0m Trial 555 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:55,826]\u001b[0m Trial 556 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:56,455]\u001b[0m Trial 557 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:57,391]\u001b[0m Trial 558 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:58,317]\u001b[0m Trial 559 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:30:59,411]\u001b[0m Trial 560 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:00,060]\u001b[0m Trial 561 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:01,047]\u001b[0m Trial 562 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:02,082]\u001b[0m Trial 563 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:02,780]\u001b[0m Trial 564 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:03,446]\u001b[0m Trial 565 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:04,130]\u001b[0m Trial 566 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:04,796]\u001b[0m Trial 567 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:05,504]\u001b[0m Trial 568 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:06,194]\u001b[0m Trial 569 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:07,437]\u001b[0m Trial 570 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:08,117]\u001b[0m Trial 571 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:12,316]\u001b[0m Trial 572 finished with value: 0.28508274755052726 and parameters: {'learning_rate': 0.34195027960463303, 'max_depth': 401, 'lambda_l1': 0.11250826243583746, 'lambda_l2': 9.176879450804209e-08, 'num_leaves': 122, 'n_estimators': 931, 'feature_fraction': 0.749171917155812, 'bagging_fraction': 0.9013274169799198, 'bagging_freq': 1, 'min_child_samples': 88}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=9.170081248026652e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.170081248026652e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.47240282940761974, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.47240282940761974\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8920898075952424, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8920898075952424\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7612513856588708, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7612513856588708\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:31:12,952]\u001b[0m Trial 573 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:13,617]\u001b[0m Trial 574 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:14,411]\u001b[0m Trial 575 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:15,142]\u001b[0m Trial 576 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:16,020]\u001b[0m Trial 577 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:16,717]\u001b[0m Trial 578 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:21,924]\u001b[0m Trial 579 finished with value: 0.28559239292857264 and parameters: {'learning_rate': 0.37164652036994844, 'max_depth': 396, 'lambda_l1': 0.12304039868251171, 'lambda_l2': 6.98035488128353e-08, 'num_leaves': 118, 'n_estimators': 841, 'feature_fraction': 0.759829137497639, 'bagging_fraction': 0.8931842338758555, 'bagging_freq': 6, 'min_child_samples': 95}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=3.2727105245989945e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2727105245989945e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.1586386004679919, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1586386004679919\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9136630112339412, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9136630112339412\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6942333120995922, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6942333120995922\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:31:22,542]\u001b[0m Trial 580 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:23,451]\u001b[0m Trial 581 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:24,221]\u001b[0m Trial 582 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:24,902]\u001b[0m Trial 583 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:25,524]\u001b[0m Trial 584 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:26,176]\u001b[0m Trial 585 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:26,993]\u001b[0m Trial 586 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:27,669]\u001b[0m Trial 587 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:28,374]\u001b[0m Trial 588 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:29,050]\u001b[0m Trial 589 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:29,685]\u001b[0m Trial 590 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:30,822]\u001b[0m Trial 591 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:31,477]\u001b[0m Trial 592 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:32,179]\u001b[0m Trial 593 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:32,908]\u001b[0m Trial 594 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:33,596]\u001b[0m Trial 595 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:34,783]\u001b[0m Trial 596 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:35,445]\u001b[0m Trial 597 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:36,143]\u001b[0m Trial 598 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:37,070]\u001b[0m Trial 599 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:37,768]\u001b[0m Trial 600 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:38,910]\u001b[0m Trial 601 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:39,511]\u001b[0m Trial 602 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:40,299]\u001b[0m Trial 603 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:41,278]\u001b[0m Trial 604 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:41,971]\u001b[0m Trial 605 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:42,612]\u001b[0m Trial 606 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:46,893]\u001b[0m Trial 607 finished with value: 0.28582572902282855 and parameters: {'learning_rate': 0.38249481432076465, 'max_depth': 454, 'lambda_l1': 0.07206816684724045, 'lambda_l2': 1.1342998983051656e-07, 'num_leaves': 186, 'n_estimators': 515, 'feature_fraction': 0.77414131837605, 'bagging_fraction': 0.9268878579528358, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=6.811846554032479e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.811846554032479e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.7090193690632376, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7090193690632376\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9001261408157891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9001261408157891\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7312259563271877, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7312259563271877\n",
     "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:31:47,550]\u001b[0m Trial 608 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:48,243]\u001b[0m Trial 609 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:49,336]\u001b[0m Trial 610 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:50,066]\u001b[0m Trial 611 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:54,370]\u001b[0m Trial 612 finished with value: 0.2857041326770656 and parameters: {'learning_rate': 0.4135897267510765, 'max_depth': 421, 'lambda_l1': 0.10088413507907254, 'lambda_l2': 0.001236521137041165, 'num_leaves': 160, 'n_estimators': 673, 'feature_fraction': 0.7179131268926683, 'bagging_fraction': 0.9082785541309089, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=4.2581019560593085e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.2581019560593085e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.19459607282140082, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19459607282140082\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9310381595011021, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9310381595011021\n",
     "[LightGBM] [Warning] feature_fraction is set=0.8050803851365608, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8050803851365608\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:31:55,209]\u001b[0m Trial 613 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:56,041]\u001b[0m Trial 614 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:56,923]\u001b[0m Trial 615 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:57,578]\u001b[0m Trial 616 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:58,258]\u001b[0m Trial 617 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:31:59,158]\u001b[0m Trial 618 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:00,109]\u001b[0m Trial 619 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:00,763]\u001b[0m Trial 620 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:01,878]\u001b[0m Trial 621 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:02,535]\u001b[0m Trial 622 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:03,693]\u001b[0m Trial 623 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:04,394]\u001b[0m Trial 624 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:05,115]\u001b[0m Trial 625 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:06,010]\u001b[0m Trial 626 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:06,718]\u001b[0m Trial 627 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:07,748]\u001b[0m Trial 628 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:08,415]\u001b[0m Trial 629 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:09,416]\u001b[0m Trial 630 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:10,072]\u001b[0m Trial 631 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:10,859]\u001b[0m Trial 632 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:11,570]\u001b[0m Trial 633 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:12,266]\u001b[0m Trial 634 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:12,953]\u001b[0m Trial 635 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:13,711]\u001b[0m Trial 636 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:14,375]\u001b[0m Trial 637 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:15,103]\u001b[0m Trial 638 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:19,392]\u001b[0m Trial 639 finished with value: 0.2859542894889776 and parameters: {'learning_rate': 0.40945494508873853, 'max_depth': 445, 'lambda_l1': 0.10591473692710048, 'lambda_l2': 4.4302151762534774e-08, 'num_leaves': 178, 'n_estimators': 2646, 'feature_fraction': 0.7355928624523055, 'bagging_fraction': 0.8996608426157737, 'bagging_freq': 1, 'min_child_samples': 89}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=8.126734429344505e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.126734429344505e-06\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.0481043839732723, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0481043839732723\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9121867213812942, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9121867213812942\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7214967809223002, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7214967809223002\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:32:20,360]\u001b[0m Trial 640 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:21,021]\u001b[0m Trial 641 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:21,657]\u001b[0m Trial 642 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:22,338]\u001b[0m Trial 643 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:23,001]\u001b[0m Trial 644 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:23,945]\u001b[0m Trial 645 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:25,046]\u001b[0m Trial 646 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:26,156]\u001b[0m Trial 647 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:27,252]\u001b[0m Trial 648 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:28,061]\u001b[0m Trial 649 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:29,378]\u001b[0m Trial 650 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:30,018]\u001b[0m Trial 651 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:30,779]\u001b[0m Trial 652 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:31,440]\u001b[0m Trial 653 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:32,104]\u001b[0m Trial 654 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:32,802]\u001b[0m Trial 655 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:33,483]\u001b[0m Trial 656 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:37,642]\u001b[0m Trial 657 finished with value: 0.2860878134813569 and parameters: {'learning_rate': 0.392700154868967, 'max_depth': 406, 'lambda_l1': 0.1105547867322984, 'lambda_l2': 3.634237160763512e-05, 'num_leaves': 170, 'n_estimators': 1746, 'feature_fraction': 0.6563986674835592, 'bagging_fraction': 0.9574464458725, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=3.0870647439780387e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.0870647439780387e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.2241375737324903, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2241375737324903\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9259775555033662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9259775555033662\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7056790411847921, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7056790411847921\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:32:38,275]\u001b[0m Trial 658 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:39,176]\u001b[0m Trial 659 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:39,841]\u001b[0m Trial 660 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:40,655]\u001b[0m Trial 661 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:41,423]\u001b[0m Trial 662 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:42,096]\u001b[0m Trial 663 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:42,746]\u001b[0m Trial 664 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:43,532]\u001b[0m Trial 665 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:46,857]\u001b[0m Trial 666 finished with value: 0.28551649970876375 and parameters: {'learning_rate': 0.33001928753062754, 'max_depth': 413, 'lambda_l1': 0.08885128808819542, 'lambda_l2': 4.704772435973511e-08, 'num_leaves': 104, 'n_estimators': 1975, 'feature_fraction': 0.7752147251060182, 'bagging_fraction': 0.9300244019643399, 'bagging_freq': 1, 'min_child_samples': 97}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=3.699103448041684e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.699103448041684e-06\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.6794322416240534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6794322416240534\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8894149566631108, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8894149566631108\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6761383841051792, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6761383841051792\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:32:47,443]\u001b[0m Trial 667 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:48,124]\u001b[0m Trial 668 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:48,832]\u001b[0m Trial 669 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:49,501]\u001b[0m Trial 670 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:50,192]\u001b[0m Trial 671 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:50,872]\u001b[0m Trial 672 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:51,862]\u001b[0m Trial 673 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:52,616]\u001b[0m Trial 674 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:53,934]\u001b[0m Trial 675 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:54,600]\u001b[0m Trial 676 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:55,490]\u001b[0m Trial 677 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:56,122]\u001b[0m Trial 678 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:56,810]\u001b[0m Trial 679 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:57,520]\u001b[0m Trial 680 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:58,219]\u001b[0m Trial 681 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:59,006]\u001b[0m Trial 682 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:32:59,699]\u001b[0m Trial 683 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:00,959]\u001b[0m Trial 684 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:01,633]\u001b[0m Trial 685 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:02,353]\u001b[0m Trial 686 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:03,341]\u001b[0m Trial 687 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:03,937]\u001b[0m Trial 688 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:04,846]\u001b[0m Trial 689 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:05,588]\u001b[0m Trial 690 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:06,272]\u001b[0m Trial 691 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:07,015]\u001b[0m Trial 692 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:07,763]\u001b[0m Trial 693 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:08,440]\u001b[0m Trial 694 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:09,302]\u001b[0m Trial 695 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:10,220]\u001b[0m Trial 696 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:11,048]\u001b[0m Trial 697 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:11,731]\u001b[0m Trial 698 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:13,013]\u001b[0m Trial 699 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:13,648]\u001b[0m Trial 700 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:14,437]\u001b[0m Trial 701 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:15,133]\u001b[0m Trial 702 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:15,849]\u001b[0m Trial 703 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:16,890]\u001b[0m Trial 704 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:17,595]\u001b[0m Trial 705 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:18,284]\u001b[0m Trial 706 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:18,959]\u001b[0m Trial 707 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:19,626]\u001b[0m Trial 708 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:21,108]\u001b[0m Trial 709 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:21,730]\u001b[0m Trial 710 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:22,842]\u001b[0m Trial 711 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:23,512]\u001b[0m Trial 712 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:24,225]\u001b[0m Trial 713 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:25,110]\u001b[0m Trial 714 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:25,763]\u001b[0m Trial 715 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:26,444]\u001b[0m Trial 716 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:27,128]\u001b[0m Trial 717 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:28,090]\u001b[0m Trial 718 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:29,111]\u001b[0m Trial 719 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:29,746]\u001b[0m Trial 720 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:30,514]\u001b[0m Trial 721 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:31,185]\u001b[0m Trial 722 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:32,387]\u001b[0m Trial 723 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:33,091]\u001b[0m Trial 724 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:33,782]\u001b[0m Trial 725 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:34,687]\u001b[0m Trial 726 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:35,502]\u001b[0m Trial 727 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:36,164]\u001b[0m Trial 728 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:36,813]\u001b[0m Trial 729 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:37,637]\u001b[0m Trial 730 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:38,552]\u001b[0m Trial 731 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:39,305]\u001b[0m Trial 732 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:40,033]\u001b[0m Trial 733 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:40,684]\u001b[0m Trial 734 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:41,750]\u001b[0m Trial 735 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:46,368]\u001b[0m Trial 736 finished with value: 0.28528360227339367 and parameters: {'learning_rate': 0.3996855068452921, 'max_depth': 378, 'lambda_l1': 0.1148039220283924, 'lambda_l2': 1.5915760373093858e-07, 'num_leaves': 193, 'n_estimators': 1306, 'feature_fraction': 0.7084167853051234, 'bagging_fraction': 0.7751695476259369, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.8326648394883892e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8326648394883892e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.4268498982116234, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4268498982116234\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8299268879857691, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8299268879857691\n",
     "[LightGBM] [Warning] feature_fraction is set=0.70110857360238, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.70110857360238\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:33:46,972]\u001b[0m Trial 737 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:47,657]\u001b[0m Trial 738 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:48,717]\u001b[0m Trial 739 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:49,636]\u001b[0m Trial 740 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:50,275]\u001b[0m Trial 741 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:51,012]\u001b[0m Trial 742 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:51,810]\u001b[0m Trial 743 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:52,748]\u001b[0m Trial 744 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:53,442]\u001b[0m Trial 745 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:58,258]\u001b[0m Trial 746 finished with value: 0.2858043601896621 and parameters: {'learning_rate': 0.44604445917573887, 'max_depth': 456, 'lambda_l1': 0.11035903393698829, 'lambda_l2': 3.2877080524921367e-07, 'num_leaves': 190, 'n_estimators': 658, 'feature_fraction': 0.675800067712452, 'bagging_fraction': 0.7966737894292265, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.5294809693793674e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.5294809693793674e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.31898109236206873, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31898109236206873\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9198583157830318, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9198583157830318\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7161719338547361, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7161719338547361\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:33:58,869]\u001b[0m Trial 747 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:33:59,500]\u001b[0m Trial 748 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:00,357]\u001b[0m Trial 749 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:01,054]\u001b[0m Trial 750 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:01,946]\u001b[0m Trial 751 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:02,619]\u001b[0m Trial 752 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:03,725]\u001b[0m Trial 753 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:08,062]\u001b[0m Trial 754 finished with value: 0.28528883282798023 and parameters: {'learning_rate': 0.4002025437597432, 'max_depth': 407, 'lambda_l1': 0.16966635345416295, 'lambda_l2': 0.0002851431274834717, 'num_leaves': 191, 'n_estimators': 1268, 'feature_fraction': 0.7768297988553182, 'bagging_fraction': 0.9137867330022371, 'bagging_freq': 1, 'min_child_samples': 97}. Best is trial 243 with value: 0.2849040072846442.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.00026179723126019895, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00026179723126019895\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.3789409017028767, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3789409017028767\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.909430476079067, subsample=1.0 will be ignored. Current value: bagging_fraction=0.909430476079067\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7905869685142057, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7905869685142057\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:34:08,702]\u001b[0m Trial 755 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:09,451]\u001b[0m Trial 756 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:10,161]\u001b[0m Trial 757 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:10,975]\u001b[0m Trial 758 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:11,657]\u001b[0m Trial 759 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:12,334]\u001b[0m Trial 760 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:12,958]\u001b[0m Trial 761 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:13,895]\u001b[0m Trial 762 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:18,311]\u001b[0m Trial 763 finished with value: 0.2849033580068632 and parameters: {'learning_rate': 0.42826126308575047, 'max_depth': 487, 'lambda_l1': 0.13227479819982219, 'lambda_l2': 2.960979077449944e-07, 'num_leaves': 195, 'n_estimators': 1830, 'feature_fraction': 0.6676326349288221, 'bagging_fraction': 0.8199438863108379, 'bagging_freq': 1, 'min_child_samples': 98}. Best is trial 763 with value: 0.2849033580068632.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=3.634609321538665e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.634609321538665e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.41318097157260003, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41318097157260003\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8148208212300221, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148208212300221\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6554574731968206, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6554574731968206\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:34:18,939]\u001b[0m Trial 764 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:19,629]\u001b[0m Trial 765 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:20,296]\u001b[0m Trial 766 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:21,232]\u001b[0m Trial 767 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:21,909]\u001b[0m Trial 768 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:22,629]\u001b[0m Trial 769 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:23,636]\u001b[0m Trial 770 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:24,326]\u001b[0m Trial 771 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:24,969]\u001b[0m Trial 772 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:25,731]\u001b[0m Trial 773 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:26,568]\u001b[0m Trial 774 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:30,523]\u001b[0m Trial 775 finished with value: 0.28589782003056063 and parameters: {'learning_rate': 0.42903402963224735, 'max_depth': 495, 'lambda_l1': 0.12388836240873576, 'lambda_l2': 5.305529835493165e-07, 'num_leaves': 128, 'n_estimators': 2127, 'feature_fraction': 0.6431852640884251, 'bagging_fraction': 0.8024642889071804, 'bagging_freq': 1, 'min_child_samples': 50}. Best is trial 763 with value: 0.2849033580068632.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.9120495704733818e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9120495704733818e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.17871181541974887, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17871181541974887\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8699291579673536, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8699291579673536\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6693532713862742, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6693532713862742\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:34:31,141]\u001b[0m Trial 776 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:32,844]\u001b[0m Trial 777 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:33,486]\u001b[0m Trial 778 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:34,196]\u001b[0m Trial 779 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:34,896]\u001b[0m Trial 780 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:35,574]\u001b[0m Trial 781 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:36,493]\u001b[0m Trial 782 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:37,348]\u001b[0m Trial 783 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:38,116]\u001b[0m Trial 784 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:38,854]\u001b[0m Trial 785 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:39,677]\u001b[0m Trial 786 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:40,320]\u001b[0m Trial 787 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:40,990]\u001b[0m Trial 788 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:41,667]\u001b[0m Trial 789 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:42,325]\u001b[0m Trial 790 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:43,421]\u001b[0m Trial 791 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:44,128]\u001b[0m Trial 792 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:44,846]\u001b[0m Trial 793 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:45,516]\u001b[0m Trial 794 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:46,193]\u001b[0m Trial 795 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:46,932]\u001b[0m Trial 796 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:47,965]\u001b[0m Trial 797 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:48,647]\u001b[0m Trial 798 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:49,335]\u001b[0m Trial 799 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:50,166]\u001b[0m Trial 800 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:50,902]\u001b[0m Trial 801 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:51,551]\u001b[0m Trial 802 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:52,271]\u001b[0m Trial 803 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:52,883]\u001b[0m Trial 804 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:53,546]\u001b[0m Trial 805 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:58,388]\u001b[0m Trial 806 finished with value: 0.28521072192290653 and parameters: {'learning_rate': 0.3614531498098397, 'max_depth': 388, 'lambda_l1': 0.11363939207889047, 'lambda_l2': 2.7657624485450528e-08, 'num_leaves': 164, 'n_estimators': 942, 'feature_fraction': 0.7620384877464277, 'bagging_fraction': 0.9114528341084662, 'bagging_freq': 1, 'min_child_samples': 93}. Best is trial 763 with value: 0.2849033580068632.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.007454985533939425, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007454985533939425\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.21909487783465095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21909487783465095\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.6690031436969819, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6690031436969819\n",
     "[LightGBM] [Warning] feature_fraction is set=0.784670201026883, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.784670201026883\n",
     "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:34:59,217]\u001b[0m Trial 807 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:34:59,899]\u001b[0m Trial 808 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:00,601]\u001b[0m Trial 809 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:01,306]\u001b[0m Trial 810 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:02,003]\u001b[0m Trial 811 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:02,724]\u001b[0m Trial 812 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:03,608]\u001b[0m Trial 813 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:04,264]\u001b[0m Trial 814 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:04,967]\u001b[0m Trial 815 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:05,892]\u001b[0m Trial 816 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:06,577]\u001b[0m Trial 817 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:10,831]\u001b[0m Trial 818 finished with value: 0.2852548471746523 and parameters: {'learning_rate': 0.3614514182570602, 'max_depth': 154, 'lambda_l1': 0.11742810793923787, 'lambda_l2': 8.6936306100759e-08, 'num_leaves': 113, 'n_estimators': 444, 'feature_fraction': 0.7259881056584222, 'bagging_fraction': 0.9307594049480413, 'bagging_freq': 1, 'min_child_samples': 95}. Best is trial 763 with value: 0.2849033580068632.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=8.432535012780234e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.432535012780234e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.27449614610183243, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27449614610183243\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9751550024968347, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9751550024968347\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7281823551146169, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7281823551146169\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:35:11,457]\u001b[0m Trial 819 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:12,138]\u001b[0m Trial 820 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:12,785]\u001b[0m Trial 821 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:16,760]\u001b[0m Trial 822 finished with value: 0.2854686593085791 and parameters: {'learning_rate': 0.37554160781771767, 'max_depth': 130, 'lambda_l1': 0.11769862823074281, 'lambda_l2': 1.1454985310760132e-07, 'num_leaves': 119, 'n_estimators': 411, 'feature_fraction': 0.7438041563618938, 'bagging_fraction': 0.9617226879305815, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 763 with value: 0.2849033580068632.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=4.2757102057929433e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.2757102057929433e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.1956612213050121, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1956612213050121\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9283306923248287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9283306923248287\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7167557753982268, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7167557753982268\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:35:17,495]\u001b[0m Trial 823 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:18,220]\u001b[0m Trial 824 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:18,927]\u001b[0m Trial 825 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:19,605]\u001b[0m Trial 826 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:20,271]\u001b[0m Trial 827 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:21,038]\u001b[0m Trial 828 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:21,729]\u001b[0m Trial 829 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:22,674]\u001b[0m Trial 830 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:23,438]\u001b[0m Trial 831 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:24,082]\u001b[0m Trial 832 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:25,076]\u001b[0m Trial 833 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:25,743]\u001b[0m Trial 834 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:26,672]\u001b[0m Trial 835 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:29,873]\u001b[0m Trial 836 finished with value: 0.28740453223589957 and parameters: {'learning_rate': 0.3868931045347761, 'max_depth': 476, 'lambda_l1': 0.07638619287307588, 'lambda_l2': 1.713474049139853e-07, 'num_leaves': 118, 'n_estimators': 599, 'feature_fraction': 0.7795114972501898, 'bagging_fraction': 0.9574153103846466, 'bagging_freq': 1, 'min_child_samples': 96}. Best is trial 763 with value: 0.2849033580068632.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=7.620671353579279e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.620671353579279e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.14528925129131165, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14528925129131165\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9024032673502126, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9024032673502126\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7139917991698747, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7139917991698747\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:35:30,633]\u001b[0m Trial 837 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:31,299]\u001b[0m Trial 838 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:32,016]\u001b[0m Trial 839 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:32,931]\u001b[0m Trial 840 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:33,566]\u001b[0m Trial 841 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:34,272]\u001b[0m Trial 842 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:34,992]\u001b[0m Trial 843 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:35,650]\u001b[0m Trial 844 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:36,651]\u001b[0m Trial 845 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:37,304]\u001b[0m Trial 846 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:38,039]\u001b[0m Trial 847 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:38,722]\u001b[0m Trial 848 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:39,487]\u001b[0m Trial 849 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:40,207]\u001b[0m Trial 850 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:44,111]\u001b[0m Trial 851 finished with value: 0.2859712439133261 and parameters: {'learning_rate': 0.3676604457447707, 'max_depth': 349, 'lambda_l1': 0.10462342794977857, 'lambda_l2': 2.6752025144209975e-07, 'num_leaves': 133, 'n_estimators': 880, 'feature_fraction': 0.7712910670248692, 'bagging_fraction': 0.9317821264931225, 'bagging_freq': 1, 'min_child_samples': 91}. Best is trial 763 with value: 0.2849033580068632.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.0737047471163055e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0737047471163055e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.1926623812963412, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1926623812963412\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.920608832357566, subsample=1.0 will be ignored. Current value: bagging_fraction=0.920608832357566\n",
     "[LightGBM] [Warning] feature_fraction is set=0.708818835781918, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.708818835781918\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:35:44,793]\u001b[0m Trial 852 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:45,477]\u001b[0m Trial 853 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:46,204]\u001b[0m Trial 854 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:46,893]\u001b[0m Trial 855 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:47,996]\u001b[0m Trial 856 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:48,724]\u001b[0m Trial 857 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:49,394]\u001b[0m Trial 858 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:50,523]\u001b[0m Trial 859 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:54,732]\u001b[0m Trial 860 finished with value: 0.28555636954233077 and parameters: {'learning_rate': 0.4670210821093029, 'max_depth': 274, 'lambda_l1': 0.13680984104654126, 'lambda_l2': 2.8225137064763732e-08, 'num_leaves': 160, 'n_estimators': 669, 'feature_fraction': 0.617618529726568, 'bagging_fraction': 0.8717839913663226, 'bagging_freq': 1, 'min_child_samples': 91}. Best is trial 763 with value: 0.2849033580068632.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=2.480423195957849e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.480423195957849e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.08018353104750793, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08018353104750793\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9124743350829505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9124743350829505\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7023030841397446, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7023030841397446\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:35:55,677]\u001b[0m Trial 861 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:56,423]\u001b[0m Trial 862 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:57,102]\u001b[0m Trial 863 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:57,924]\u001b[0m Trial 864 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:58,629]\u001b[0m Trial 865 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:35:59,341]\u001b[0m Trial 866 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:00,065]\u001b[0m Trial 867 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:01,345]\u001b[0m Trial 868 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:02,074]\u001b[0m Trial 869 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:02,903]\u001b[0m Trial 870 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:03,599]\u001b[0m Trial 871 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:04,392]\u001b[0m Trial 872 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:05,042]\u001b[0m Trial 873 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:05,975]\u001b[0m Trial 874 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:06,683]\u001b[0m Trial 875 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:07,349]\u001b[0m Trial 876 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:08,141]\u001b[0m Trial 877 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:08,815]\u001b[0m Trial 878 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:09,501]\u001b[0m Trial 879 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:10,751]\u001b[0m Trial 880 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:11,410]\u001b[0m Trial 881 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:12,123]\u001b[0m Trial 882 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:12,772]\u001b[0m Trial 883 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:13,452]\u001b[0m Trial 884 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:14,149]\u001b[0m Trial 885 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:14,814]\u001b[0m Trial 886 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:15,870]\u001b[0m Trial 887 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:17,183]\u001b[0m Trial 888 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:17,976]\u001b[0m Trial 889 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:18,638]\u001b[0m Trial 890 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:19,346]\u001b[0m Trial 891 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:23,279]\u001b[0m Trial 892 finished with value: 0.2857585020457934 and parameters: {'learning_rate': 0.39170486841297136, 'max_depth': 391, 'lambda_l1': 0.0996853973081099, 'lambda_l2': 3.3925927659655535e-07, 'num_leaves': 141, 'n_estimators': 1203, 'feature_fraction': 0.7192300788351427, 'bagging_fraction': 0.8860286756134946, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 763 with value: 0.2849033580068632.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=0.00017457588964568812, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00017457588964568812\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.05376719602725752, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05376719602725752\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9084809767025439, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9084809767025439\n",
     "[LightGBM] [Warning] feature_fraction is set=0.684894942330867, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.684894942330867\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:36:24,016]\u001b[0m Trial 893 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:24,731]\u001b[0m Trial 894 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:25,410]\u001b[0m Trial 895 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:26,170]\u001b[0m Trial 896 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:26,894]\u001b[0m Trial 897 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:27,575]\u001b[0m Trial 898 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:33,523]\u001b[0m Trial 899 finished with value: 0.28531251118969364 and parameters: {'learning_rate': 0.3974747850696594, 'max_depth': 500, 'lambda_l1': 0.09535320317541289, 'lambda_l2': 1.7414536145550778e-07, 'num_leaves': 152, 'n_estimators': 903, 'feature_fraction': 0.7251742073106893, 'bagging_fraction': 0.8723502207889915, 'bagging_freq': 3, 'min_child_samples': 96}. Best is trial 763 with value: 0.2849033580068632.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=1.8885023435676776e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8885023435676776e-07\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.036501278780292246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.036501278780292246\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.8698437519282312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8698437519282312\n",
     "[LightGBM] [Warning] feature_fraction is set=0.7301688048370906, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7301688048370906\n",
     "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:36:34,764]\u001b[0m Trial 900 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:35,549]\u001b[0m Trial 901 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:36,314]\u001b[0m Trial 902 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:37,109]\u001b[0m Trial 903 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:37,875]\u001b[0m Trial 904 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:38,600]\u001b[0m Trial 905 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:39,341]\u001b[0m Trial 906 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:40,082]\u001b[0m Trial 907 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:40,854]\u001b[0m Trial 908 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:41,765]\u001b[0m Trial 909 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:42,476]\u001b[0m Trial 910 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:43,177]\u001b[0m Trial 911 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:43,945]\u001b[0m Trial 912 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:44,715]\u001b[0m Trial 913 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:45,429]\u001b[0m Trial 914 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:46,105]\u001b[0m Trial 915 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:47,290]\u001b[0m Trial 916 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:48,080]\u001b[0m Trial 917 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:49,070]\u001b[0m Trial 918 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:49,811]\u001b[0m Trial 919 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:50,466]\u001b[0m Trial 920 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:51,172]\u001b[0m Trial 921 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:52,422]\u001b[0m Trial 922 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:53,163]\u001b[0m Trial 923 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:53,836]\u001b[0m Trial 924 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:54,525]\u001b[0m Trial 925 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:55,250]\u001b[0m Trial 926 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:56,024]\u001b[0m Trial 927 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:56,703]\u001b[0m Trial 928 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:57,450]\u001b[0m Trial 929 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:58,472]\u001b[0m Trial 930 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:59,280]\u001b[0m Trial 931 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:36:59,944]\u001b[0m Trial 932 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:00,767]\u001b[0m Trial 933 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:01,517]\u001b[0m Trial 934 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:02,565]\u001b[0m Trial 935 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:03,237]\u001b[0m Trial 936 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:04,162]\u001b[0m Trial 937 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:05,468]\u001b[0m Trial 938 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:06,158]\u001b[0m Trial 939 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:06,841]\u001b[0m Trial 940 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:07,594]\u001b[0m Trial 941 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:08,374]\u001b[0m Trial 942 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:09,117]\u001b[0m Trial 943 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:09,833]\u001b[0m Trial 944 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:10,688]\u001b[0m Trial 945 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:11,338]\u001b[0m Trial 946 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:12,033]\u001b[0m Trial 947 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:12,949]\u001b[0m Trial 948 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:13,639]\u001b[0m Trial 949 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:14,327]\u001b[0m Trial 950 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:15,237]\u001b[0m Trial 951 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:16,251]\u001b[0m Trial 952 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:16,880]\u001b[0m Trial 953 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:17,594]\u001b[0m Trial 954 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:18,335]\u001b[0m Trial 955 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:18,995]\u001b[0m Trial 956 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:20,083]\u001b[0m Trial 957 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:20,749]\u001b[0m Trial 958 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:21,439]\u001b[0m Trial 959 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:22,153]\u001b[0m Trial 960 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:22,893]\u001b[0m Trial 961 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:23,592]\u001b[0m Trial 962 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:24,484]\u001b[0m Trial 963 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:25,297]\u001b[0m Trial 964 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:25,961]\u001b[0m Trial 965 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:26,651]\u001b[0m Trial 966 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:27,308]\u001b[0m Trial 967 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:28,016]\u001b[0m Trial 968 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:28,820]\u001b[0m Trial 969 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:29,701]\u001b[0m Trial 970 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:30,508]\u001b[0m Trial 971 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:31,195]\u001b[0m Trial 972 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:31,960]\u001b[0m Trial 973 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:32,689]\u001b[0m Trial 974 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:33,367]\u001b[0m Trial 975 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:34,094]\u001b[0m Trial 976 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:34,792]\u001b[0m Trial 977 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:35,868]\u001b[0m Trial 978 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:36,522]\u001b[0m Trial 979 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:37,191]\u001b[0m Trial 980 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:38,145]\u001b[0m Trial 981 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:39,302]\u001b[0m Trial 982 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:40,062]\u001b[0m Trial 983 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:40,744]\u001b[0m Trial 984 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:41,416]\u001b[0m Trial 985 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:44,634]\u001b[0m Trial 986 finished with value: 0.2861818962146115 and parameters: {'learning_rate': 0.35282864524788166, 'max_depth': 354, 'lambda_l1': 0.07452531021388555, 'lambda_l2': 1.7001569184804915e-05, 'num_leaves': 115, 'n_estimators': 975, 'feature_fraction': 0.7229585976370109, 'bagging_fraction': 0.9459682905583495, 'bagging_freq': 1, 'min_child_samples': 85}. Best is trial 763 with value: 0.2849033580068632.\u001b[0m\n"
    ]
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "[LightGBM] [Warning] lambda_l2 is set=9.87100288517887e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.87100288517887e-08\n",
     "[LightGBM] [Warning] lambda_l1 is set=0.02682407260581923, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02682407260581923\n",
     "[LightGBM] [Warning] bagging_fraction is set=0.9828502845556674, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9828502845556674\n",
     "[LightGBM] [Warning] feature_fraction is set=0.6106577052742163, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6106577052742163\n",
     "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
    ]
   },
   {
    "name": "stderr",
    "output_type": "stream",
    "text": [
     "\u001b[32m[I 2025-10-14 16:37:45,365]\u001b[0m Trial 987 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:46,067]\u001b[0m Trial 988 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:46,717]\u001b[0m Trial 989 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:47,439]\u001b[0m Trial 990 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:48,162]\u001b[0m Trial 991 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:49,051]\u001b[0m Trial 992 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:49,770]\u001b[0m Trial 993 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:50,452]\u001b[0m Trial 994 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:51,167]\u001b[0m Trial 995 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:51,880]\u001b[0m Trial 996 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:52,572]\u001b[0m Trial 997 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:53,240]\u001b[0m Trial 998 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
     "\u001b[32m[I 2025-10-14 16:37:54,203]\u001b[0m Trial 999 pruned. Trial was pruned at iteration 13.\u001b[0m\n"
    ]
   }
  ],
  "source": [
   "study = optuna.create_study(sampler=TPESampler(), direction='minimize', pruner=optuna.pruners.MedianPruner(n_warmup_steps=5))\n",
   "study.optimize(objective, n_trials=1000, gc_after_trial=True)"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 44,
  "metadata": {
   "execution": {
    "iopub.execute_input": "2025-10-14T16:47:53.960069Z",
    "iopub.status.busy": "2025-10-14T16:47:53.959734Z",
    "iopub.status.idle": "2025-10-14T16:47:54.127570Z",
    "shell.execute_reply": "2025-10-14T16:47:54.126837Z",
    "shell.execute_reply.started": "2025-10-14T16:47:53.960036Z"
   }
  },
  "outputs": [
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "Number of finished trials: 1000\n",
     "Best trial: {'learning_rate': 0.42826126308575047, 'max_depth': 487, 'lambda_l1': 0.13227479819982219, 'lambda_l2': 2.960979077449944e-07, 'num_leaves': 195, 'n_estimators': 1830, 'feature_fraction': 0.6676326349288221, 'bagging_fraction': 0.8199438863108379, 'bagging_freq': 1, 'min_child_samples': 98}\n"
    ]
   }
  ],
  "source": [
   "print('Number of finished trials:', len(study.trials))\n",
   "print('Best trial:', study.best_trial.params)"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 45,
  "metadata": {
   "execution": {
    "iopub.execute_input": "2025-10-14T16:47:56.708557Z",
    "iopub.status.busy": "2025-10-14T16:47:56.708265Z",
    "iopub.status.idle": "2025-10-14T16:47:56.884329Z",
    "shell.execute_reply": "2025-10-14T16:47:56.883482Z",
    "shell.execute_reply.started": "2025-10-14T16:47:56.708526Z"
   }
  },
  "outputs": [
   {
    "data": {
     "text/html": [
      "<div>                            <div id=\"765283a7-eaec-4a1e-8e10-99c63cf7492b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"765283a7-eaec-4a1e-8e10-99c63cf7492b\")) {                    Plotly.newPlot(                        \"765283a7-eaec-4a1e-8e10-99c63cf7492b\",                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 13, 19, 26, 31, 37, 42, 51, 57, 64, 71, 75, 81, 83, 103, 112, 114, 116, 123, 124, 125, 128, 133, 140, 147, 149, 151, 162, 163, 171, 172, 173, 180, 184, 203, 210, 213, 217, 218, 220, 227, 228, 229, 232, 233, 235, 237, 241, 243, 244, 252, 254, 255, 256, 260, 267, 270, 271, 278, 282, 283, 284, 287, 290, 300, 301, 303, 319, 325, 330, 334, 353, 358, 366, 371, 372, 383, 406, 409, 471, 518, 541, 572, 579, 607, 612, 639, 657, 666, 736, 746, 754, 763, 775, 806, 818, 822, 836, 851, 860, 892, 899, 986], \"y\": [0.28798153505177665, 0.28646098277543214, 0.28728935437818187, 0.2875894067771836, 0.28591438162011645, 0.2869687332185955, 0.28707515128131106, 0.28923397141825347, 0.28976819339684984, 0.28531781574642806, 0.28560327248253203, 0.2865797770708367, 0.2874400574561271, 0.2897950355979398, 0.28911765818530444, 0.28736056697664375, 0.2861566962719253, 0.28563344004112784, 0.28512803188594105, 0.2858794012990416, 0.2856615619050895, 0.2860817063467663, 0.2862077174552081, 0.28641487918078584, 0.286310692607657, 0.28619005950450715, 0.28572778724298903, 0.2852870373821442, 0.2862962554660894, 0.28576064663202577, 0.2863302713522494, 0.2863982411569646, 0.2851116770788378, 0.2861642191215349, 0.28580649465992725, 0.28638859583635357, 0.2859886056038321, 0.28631923772231666, 0.28569828794266144, 0.2864599840942761, 0.28576291814307964, 0.28605193160896114, 0.2854688073738006, 0.2852474530414222, 0.2853698470617397, 0.2852169829768244, 0.2850843049398256, 0.28530647985836977, 0.2853076348376256, 0.2852085088447463, 0.28547997563271166, 0.2854560783611736, 0.2849040072846442, 0.28500572299678617, 0.2855961177708826, 0.2853727174702844, 0.28553033496703834, 0.2854725646711681, 0.28536079599924297, 0.28547261353609066, 0.2851728913103773, 0.28571488279495827, 0.2856634094272277, 0.28537159787613375, 0.2853059092876788, 0.2852184984540954, 0.28581422990094457, 0.2860010988538534, 0.28552939900302526, 0.28578398589108883, 0.28498429328671604, 0.2855951282660909, 0.2854817337937833, 0.28544848226880254, 0.28581043851800747, 0.2853791514386664, 0.2852592414563754, 0.2858115429578009, 0.28548337350778535, 0.28548303500565136, 0.28539021776540624, 0.28538227594471266, 0.28553438508624257, 0.2851105586477252, 0.28561533643875797, 0.2856257622796934, 0.28508274755052726, 0.28559239292857264, 0.28582572902282855, 0.2857041326770656, 0.2859542894889776, 0.2860878134813569, 0.28551649970876375, 0.28528360227339367, 0.2858043601896621, 0.28528883282798023, 0.2849033580068632, 0.28589782003056063, 0.28521072192290653, 0.2852548471746523, 0.2854686593085791, 0.28740453223589957, 0.2859712439133261, 0.28555636954233077, 0.2857585020457934, 0.28531251118969364, 0.2861818962146115]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 13, 19, 26, 31, 37, 42, 51, 57, 64, 71, 75, 81, 83, 103, 112, 114, 116, 123, 124, 125, 128, 133, 140, 147, 149, 151, 162, 163, 171, 172, 173, 180, 184, 203, 210, 213, 217, 218, 220, 227, 228, 229, 232, 233, 235, 237, 241, 243, 244, 252, 254, 255, 256, 260, 267, 270, 271, 278, 282, 283, 284, 287, 290, 300, 301, 303, 319, 325, 330, 334, 353, 358, 366, 371, 372, 383, 406, 409, 471, 518, 541, 572, 579, 607, 612, 639, 657, 666, 736, 746, 754, 763, 775, 806, 818, 822, 836, 851, 860, 892, 899, 986], \"y\": [0.28798153505177665, 0.28646098277543214, 0.28646098277543214, 0.28646098277543214, 0.28591438162011645, 0.28591438162011645, 0.28591438162011645, 0.28591438162011645, 0.28591438162011645, 0.28531781574642806, 0.28531781574642806, 0.28531781574642806, 0.28531781574642806, 0.28531781574642806, 0.28531781574642806, 0.28531781574642806, 0.28531781574642806, 0.28531781574642806, 0.28512803188594105, 0.28512803188594105, 0.28512803188594105, 0.28512803188594105, 0.28512803188594105, 0.28512803188594105, 0.28512803188594105, 0.28512803188594105, 0.28512803188594105, 0.28512803188594105, 0.28512803188594105, 0.28512803188594105, 0.28512803188594105, 0.28512803188594105, 0.2851116770788378, 0.2851116770788378, 0.2851116770788378, 0.2851116770788378, 0.2851116770788378, 0.2851116770788378, 0.2851116770788378, 0.2851116770788378, 0.2851116770788378, 0.2851116770788378, 0.2851116770788378, 0.2851116770788378, 0.2851116770788378, 0.2851116770788378, 0.2850843049398256, 0.2850843049398256, 0.2850843049398256, 0.2850843049398256, 0.2850843049398256, 0.2850843049398256, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849040072846442, 0.2849033580068632, 0.2849033580068632, 0.2849033580068632, 0.2849033580068632, 0.2849033580068632, 0.2849033580068632, 0.2849033580068632, 0.2849033580068632, 0.2849033580068632, 0.2849033580068632, 0.2849033580068632]}],                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
      "                            \n",
      "var gd = document.getElementById('765283a7-eaec-4a1e-8e10-99c63cf7492b');\n",
      "var x = new MutationObserver(function (mutations, observer) {{\n",
      "        var display = window.getComputedStyle(gd).display;\n",
      "        if (!display || display === 'none') {{\n",
      "            console.log([gd, 'removed!']);\n",
      "            Plotly.purge(gd);\n",
      "            observer.disconnect();\n",
      "        }}\n",
      "}});\n",
      "\n",
      "// Listen for the removal of the full notebook cells\n",
      "var notebookContainer = gd.closest('#notebook-container');\n",
      "if (notebookContainer) {{\n",
      "    x.observe(notebookContainer, {childList: true});\n",
      "}}\n",
      "\n",
      "// Listen for the clearing of the current output cell\n",
      "var outputEl = gd.closest('.output');\n",
      "if (outputEl) {{\n",
      "    x.observe(outputEl, {childList: true});\n",
      "}}\n",
      "\n",
      "                        })                };                });            </script>        </div>"
     ]
    },
    "metadata": {},
    "output_type": "display_data"
   }
  ],
  "source": [
   "optuna.visualization.plot_optimization_history(study)"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 46,
  "metadata": {
   "execution": {
    "iopub.execute_input": "2025-10-14T16:48:02.052975Z",
    "iopub.status.busy": "2025-10-14T16:48:02.052669Z",
    "iopub.status.idle": "2025-10-14T16:48:08.662012Z",
    "shell.execute_reply": "2025-10-14T16:48:08.661204Z",
    "shell.execute_reply.started": "2025-10-14T16:48:02.052948Z"
   }
  },
  "outputs": [
   {
    "data": {
     "text/html": [
      "<div>                            <div id=\"338ed193-b0a2-4cb5-9186-692a2f423e08\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"338ed193-b0a2-4cb5-9186-692a2f423e08\")) {                    Plotly.newPlot(                        \"338ed193-b0a2-4cb5-9186-692a2f423e08\",                        [{\"cliponaxis\": false, \"hovertemplate\": [\"lambda_l2 (LogUniformDistribution): 1.699813563187075e-05<extra></extra>\", \"bagging_freq (IntUniformDistribution): 0.0008667601108231219<extra></extra>\", \"min_child_samples (IntUniformDistribution): 0.049522012934812794<extra></extra>\", \"num_leaves (IntUniformDistribution): 0.0651237094017497<extra></extra>\", \"max_depth (IntUniformDistribution): 0.08873863766742687<extra></extra>\", \"n_estimators (IntUniformDistribution): 0.09064601787157255<extra></extra>\", \"bagging_fraction (UniformDistribution): 0.09443759649274011<extra></extra>\", \"learning_rate (LogUniformDistribution): 0.15418690528146844<extra></extra>\", \"feature_fraction (UniformDistribution): 0.1695772943525679<extra></extra>\", \"lambda_l1 (LogUniformDistribution): 0.2868840677512066<extra></extra>\"], \"marker\": {\"color\": [\"rgb(8,48,107)\", \"rgb(8,81,156)\", \"rgb(8,81,156)\", \"rgb(8,81,156)\", \"rgb(8,81,156)\", \"rgb(8,81,156)\", \"rgb(8,48,107)\", \"rgb(8,48,107)\", \"rgb(8,48,107)\", \"rgb(8,48,107)\"]}, \"orientation\": \"h\", \"text\": [\"1.699813563187075e-05\", \"0.0008667601108231219\", \"0.049522012934812794\", \"0.0651237094017497\", \"0.08873863766742687\", \"0.09064601787157255\", \"0.09443759649274011\", \"0.15418690528146844\", \"0.1695772943525679\", \"0.2868840677512066\"], \"textposition\": \"outside\", \"texttemplate\": \"%{text:.2f}\", \"type\": \"bar\", \"x\": [1.699813563187075e-05, 0.0008667601108231219, 0.049522012934812794, 0.0651237094017497, 0.08873863766742687, 0.09064601787157255, 0.09443759649274011, 0.15418690528146844, 0.1695772943525679, 0.2868840677512066], \"y\": [\"lambda_l2\", \"bagging_freq\", \"min_child_samples\", \"num_leaves\", \"max_depth\", \"n_estimators\", \"bagging_fraction\", \"learning_rate\", \"feature_fraction\", \"lambda_l1\"]}],                        {\"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Hyperparameter Importances\"}, \"xaxis\": {\"title\": {\"text\": \"Importance for Objective Value\"}}, \"yaxis\": {\"title\": {\"text\": \"Hyperparameter\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
      "                            \n",
      "var gd = document.getElementById('338ed193-b0a2-4cb5-9186-692a2f423e08');\n",
      "var x = new MutationObserver(function (mutations, observer) {{\n",
      "        var display = window.getComputedStyle(gd).display;\n",
      "        if (!display || display === 'none') {{\n",
      "            console.log([gd, 'removed!']);\n",
      "            Plotly.purge(gd);\n",
      "            observer.disconnect();\n",
      "        }}\n",
      "}});\n",
      "\n",
      "// Listen for the removal of the full notebook cells\n",
      "var notebookContainer = gd.closest('#notebook-container');\n",
      "if (notebookContainer) {{\n",
      "    x.observe(notebookContainer, {childList: true});\n",
      "}}\n",
      "\n",
      "// Listen for the clearing of the current output cell\n",
      "var outputEl = gd.closest('.output');\n",
      "if (outputEl) {{\n",
      "    x.observe(outputEl, {childList: true});\n",
      "}}\n",
      "\n",
      "                        })                };                });            </script>        </div>"
     ]
    },
    "metadata": {},
    "output_type": "display_data"
   }
  ],
  "source": [
   "optuna.visualization.plot_param_importances(study)"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 47,
  "metadata": {
   "execution": {
    "iopub.execute_input": "2025-10-14T16:48:26.263668Z",
    "iopub.status.busy": "2025-10-14T16:48:26.263371Z",
    "iopub.status.idle": "2025-10-14T16:48:26.269032Z",
    "shell.execute_reply": "2025-10-14T16:48:26.268195Z",
    "shell.execute_reply.started": "2025-10-14T16:48:26.263643Z"
   }
  },
  "outputs": [
   {
    "data": {
     "text/plain": [
      "{'learning_rate': 0.42826126308575047,\n",
      " 'max_depth': 487,\n",
      " 'lambda_l1': 0.13227479819982219,\n",
      " 'lambda_l2': 2.960979077449944e-07,\n",
      " 'num_leaves': 195,\n",
      " 'n_estimators': 1830,\n",
      " 'feature_fraction': 0.6676326349288221,\n",
      " 'bagging_fraction': 0.8199438863108379,\n",
      " 'bagging_freq': 1,\n",
      " 'min_child_samples': 98}"
     ]
    },
    "execution_count": 47,
    "metadata": {},
    "output_type": "execute_result"
   }
  ],
  "source": [
   "best_params = study.best_params\n",
   "best_params"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "# Submission"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "execution": {
    "iopub.status.busy": "2025-10-14T14:49:11.051185Z",
    "iopub.status.idle": "2025-10-14T14:49:11.051524Z",
    "shell.execute_reply": "2025-10-14T14:49:11.051370Z"
   }
  },
  "outputs": [],
  "source": [
   "test_data_set_final = test_data_set.drop(['stock_id', 'time_id'], axis = 1)\n",
   "\n",
   "y_pred = test_data_set_final[['row_id']]\n",
   "X_test = test_data_set_final.drop(['row_id'], axis = 1)"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "execution": {
    "iopub.status.busy": "2025-10-14T14:49:11.052271Z",
    "iopub.status.idle": "2025-10-14T14:49:11.052593Z",
    "shell.execute_reply": "2025-10-14T14:49:11.052436Z"
   }
  },
  "outputs": [],
  "source": [
   "X_test"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "execution": {
    "iopub.status.busy": "2025-10-14T14:49:11.053416Z",
    "iopub.status.idle": "2025-10-14T14:49:11.053743Z",
    "shell.execute_reply": "2025-10-14T14:49:11.053592Z"
   }
  },
  "outputs": [],
  "source": [
   "y_pred = y_pred.assign(target = clf.predict(X_test))\n",
   "y_pred.to_csv('submission.csv',index = False)"
  ]
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
   "# Model Evalusation"
  ]
 },
 {
  "cell_type": "code",
  "execution_count": 55,
  "metadata": {
   "execution": {
    "iopub.execute_input": "2025-10-14T16:53:35.483356Z",
    "iopub.status.busy": "2025-10-14T16:53:35.483037Z",
    "iopub.status.idle": "2025-10-14T16:54:14.573755Z",
    "shell.execute_reply": "2025-10-14T16:54:14.572902Z",
    "shell.execute_reply.started": "2025-10-14T16:53:35.483330Z"
   }
  },
  "outputs": [
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "Preparing data...\n",
     "Data preparation completed: X(428932, 9), y(428932,)\n",
     "Feature columns: ['log_return1', 'bas', 'log_return2', 'log_return_bid_price1', 'log_return_ask_price1', 'log_return_bid_size1', 'log_return_ask_size1', 'log_ask_1_div_bid_1', 'log_ask_1_div_bid_1_size']\n",
     "Final data shapes:\n",
     "X_train: (343145, 9), y_train: (343145,)\n",
     "X_test: (85787, 9), y_test: (85787,)\n",
     "\n",
     "==================================================\n",
     "Evaluating Baseline XGBoost Model Performance...\n",
     "==================================================\n",
     "\n",
     "=== Baseline XGBoost Performance Evaluation ===\n",
     "\n",
     "Training set shape: X_train(343145, 9), y_train(343145,)\n",
     "Test set shape: X_test(85787, 9), y_test(85787,)\n",
     "Training Time: 1.44 seconds\n",
     "Prediction shapes: y_train_pred(343145,), y_test_pred(85787,)\n",
     "Training R2: 0.82954\n",
     "Test R2: 0.78763\n",
     "Overfitting Gap (Train R2 - Test R2): 0.04191\n",
     "Training RMSPE: 0.28925\n",
     "Test RMSPE: 0.30091\n",
     "\n",
     "=== Baseline XGBoost Cross-Validation Evaluation ===\n",
     "\n",
     "Data shape: X(343145, 9), y(343145,)\n",
     "Cross-validation time: 8.08 seconds\n",
     "Cross-validation R2 scores:\n",
     "  Fold scores: ['0.78957', '0.78818', '0.78469']\n",
     "  Mean R2: 0.78748 (+/- 0.00411)\n",
     "  Standard deviation: 0.00206\n",
     "\n",
     "==================================================\n",
     "Evaluating LightGBM Model Performance...\n",
     "==================================================\n",
     "\n",
     "=== LightGBM Performance Evaluation ===\n",
     "\n",
     "Training set shape: X_train(343145, 9), y_train(343145,)\n",
     "Test set shape: X_test(85787, 9), y_test(85787,)\n",
     "Training Time: 3.57 seconds\n",
     "Prediction shapes: y_train_pred(343145,), y_test_pred(85787,)\n",
     "Training R2: 0.82388\n",
     "Test R2: 0.78770\n",
     "Overfitting Gap (Train R2 - Test R2): 0.03618\n",
     "Training RMSPE: 0.29050\n",
     "Test RMSPE: 0.30211\n",
     "\n",
     "=== LightGBM Cross-Validation Evaluation ===\n",
     "\n",
     "Data shape: X(343145, 9), y(343145,)\n",
     "Cross-validation time: 8.50 seconds\n",
     "Cross-validation R2 scores:\n",
     "  Fold scores: ['0.79070', '0.78945', '0.78501']\n",
     "  Mean R2: 0.78839 (+/- 0.00488)\n",
     "  Standard deviation: 0.00244\n",
     "\n",
     "==================================================\n",
     "Evaluating Tuned XGBoost Model Performance...\n",
     "==================================================\n",
     "\n",
     "=== Tuned XGBoost Performance Evaluation ===\n",
     "\n",
     "Training set shape: X_train(343145, 9), y_train(343145,)\n",
     "Test set shape: X_test(85787, 9), y_test(85787,)\n",
     "Training Time: 2.80 seconds\n",
     "Prediction shapes: y_train_pred(343145,), y_test_pred(85787,)\n",
     "Training R2: 0.79470\n",
     "Test R2: 0.78825\n",
     "Overfitting Gap (Train R2 - Test R2): 0.00646\n",
     "Training RMSPE: 0.30425\n",
     "Test RMSPE: 0.30451\n",
     "\n",
     "=== Tuned XGBoost Cross-Validation Evaluation ===\n",
     "\n",
     "Data shape: X(343145, 9), y(343145,)\n",
     "Cross-validation time: 4.51 seconds\n",
     "Cross-validation R2 scores:\n",
     "  Fold scores: ['0.78640', '0.78572', '0.78155']\n",
     "  Mean R2: 0.78456 (+/- 0.00428)\n",
     "  Standard deviation: 0.00214\n",
     "\n",
     "============================================================\n",
     "Model Performance Summary\n",
     "============================================================\n",
     "              Model  Training Time (s)  Train R2  Test R2  Overfitting Gap  \\\n",
     "0  Baseline XGBoost            1.43806   0.82954  0.78763          0.04191   \n",
     "1          LightGBM            3.57071   0.82388  0.78770          0.03618   \n",
     "2     Tuned XGBoost            2.79502   0.79470  0.78825          0.00646   \n",
     "\n",
     "   CV Mean R2  CV Std R2  Test RMSPE  \n",
     "0     0.78748    0.00206     0.30091  \n",
     "1     0.78839    0.00244     0.30211  \n",
     "2     0.78456    0.00214     0.30451  \n"
    ]
   },
   {
    "data": {
     "image/png": "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\n",
     "text/plain": [
      "<Figure size 1080x720 with 4 Axes>"
     ]
    },
    "metadata": {
     "needs_background": "light"
    },
    "output_type": "display_data"
   },
   {
    "name": "stdout",
    "output_type": "stream",
    "text": [
     "\n",
     "============================================================\n",
     "Evaluation Completed!\n",
     "============================================================\n",
     "\n",
     "Key Conclusions:\n",
     "- Best Model: Tuned XGBoost (Test R2: 0.78825)\n",
     "- Best Model RMSPE: 0.30451\n",
     "- Least Overfitting Model: Tuned XGBoost\n",
     "- Fastest Training Model: Baseline XGBoost\n",
     "\n",
     "Detailed Analysis:\n",
     "- Cross-validation consistency:\n",
     "  Baseline XGBoost: CV Std = 0.00206 (High consistency)\n",
     "  LightGBM: CV Std = 0.00244 (High consistency)\n",
     "  Tuned XGBoost: CV Std = 0.00214 (High consistency)\n",
     "- Overfitting analysis:\n",
     "  Baseline XGBoost: Overfitting gap = 0.04191 (Low overfitting)\n",
     "  LightGBM: Overfitting gap = 0.03618 (Low overfitting)\n",
     "  Tuned XGBoost: Overfitting gap = 0.00646 (Low overfitting)\n"
    ]
   }
  ],
  "source": [
   "from sklearn.model_selection import cross_val_score, train_test_split\n",
   "from sklearn.metrics import r2_score\n",
   "import matplotlib.pyplot as plt\n",
   "\n",
   "# Fixed evaluation function\n",
   "def evaluate_model_performance(model, X_train, X_test, y_train, y_test, model_name=\"Model\"):\n",
   "    \"\"\"\n",
   "    Evaluate model performance including training time, R2 scores and overfitting gap\n",
   "    \"\"\"\n",
   "    print(f\"\\n=== {model_name} Performance Evaluation ===\\n\")\n",
   "    \n",
   "    # Ensure correct data format\n",
   "    X_train = np.array(X_train) if not isinstance(X_train, np.ndarray) else X_train\n",
   "    X_test = np.array(X_test) if not isinstance(X_test, np.ndarray) else X_test\n",
   "    y_train = np.array(y_train) if not isinstance(y_train, np.ndarray) else y_train\n",
   "    y_test = np.array(y_test) if not isinstance(y_test, np.ndarray) else y_test\n",
   "    \n",
   "    print(f\"Training set shape: X_train{X_train.shape}, y_train{y_train.shape}\")\n",
   "    print(f\"Test set shape: X_test{X_test.shape}, y_test{y_test.shape}\")\n",
   "    \n",
   "    # Training time\n",
   "    start_time = time.time()\n",
   "    model.fit(X_train, y_train)\n",
   "    training_time = time.time() - start_time\n",
   "    print(f\"Training Time: {training_time:.2f} seconds\")\n",
   "    \n",
   "    # Training and test predictions\n",
   "    y_train_pred = model.predict(X_train)\n",
   "    y_test_pred = model.predict(X_test)\n",
   "    \n",
   "    print(f\"Prediction shapes: y_train_pred{y_train_pred.shape}, y_test_pred{y_test_pred.shape}\")\n",
   "    \n",
   "    # R2 scores\n",
   "    train_r2 = r2_score(y_train, y_train_pred)\n",
   "    test_r2 = r2_score(y_test, y_test_pred)\n",
   "    print(f\"Training R2: {train_r2:.5f}\")\n",
   "    print(f\"Test R2: {test_r2:.5f}\")\n",
   "    \n",
   "    # Overfitting gap\n",
   "    overfitting_gap = train_r2 - test_r2\n",
   "    print(f\"Overfitting Gap (Train R2 - Test R2): {overfitting_gap:.5f}\")\n",
   "    \n",
   "    # RMSPE\n",
   "    train_rmspe = rmspe(y_train, y_train_pred)\n",
   "    test_rmspe = rmspe(y_test, y_test_pred)\n",
   "    print(f\"Training RMSPE: {train_rmspe:.5f}\")\n",
   "    print(f\"Test RMSPE: {test_rmspe:.5f}\")\n",
   "    \n",
   "    return {\n",
   "        'training_time': training_time,\n",
   "        'train_r2': train_r2,\n",
   "        'test_r2': test_r2,\n",
   "        'overfitting_gap': overfitting_gap,\n",
   "        'train_rmspe': train_rmspe,\n",
   "        'test_rmspe': test_rmspe\n",
   "    }\n",
   "\n",
   "# Cross-validation evaluation function\n",
   "def evaluate_cross_validation(model, X, y, cv_folds=5, model_name=\"Model\"):\n",
   "    \"\"\"\n",
   "    Evaluate model performance using cross-validation\n",
   "    \"\"\"\n",
   "    print(f\"\\n=== {model_name} Cross-Validation Evaluation ===\\n\")\n",
   "    \n",
   "    # Ensure correct data format\n",
   "    X = np.array(X) if not isinstance(X, np.ndarray) else X\n",
   "    y = np.array(y) if not isinstance(y, np.ndarray) else y\n",
   "    \n",
   "    print(f\"Data shape: X{X.shape}, y{y.shape}\")\n",
   "    \n",
   "    start_time = time.time()\n",
   "    \n",
   "    # Cross-validation with R2 scoring\n",
   "    try:\n",
   "        cv_scores = cross_val_score(model, X, y, cv=cv_folds, scoring='r2', n_jobs=-1)\n",
   "    except Exception as e:\n",
   "        print(f\"Cross-validation error: {e}\")\n",
   "        print(\"Using single thread for cross-validation...\")\n",
   "        cv_scores = cross_val_score(model, X, y, cv=cv_folds, scoring='r2', n_jobs=1)\n",
   "    \n",
   "    cv_time = time.time() - start_time\n",
   "    \n",
   "    print(f\"Cross-validation time: {cv_time:.2f} seconds\")\n",
   "    print(f\"Cross-validation R2 scores:\")\n",
   "    print(f\"  Fold scores: {[f'{score:.5f}' for score in cv_scores]}\")\n",
   "    print(f\"  Mean R2: {cv_scores.mean():.5f} (+/- {cv_scores.std() * 2:.5f})\")\n",
   "    print(f\"  Standard deviation: {cv_scores.std():.5f}\")\n",
   "    \n",
   "    return {\n",
   "        'cv_mean_r2': cv_scores.mean(),\n",
   "        'cv_std_r2': cv_scores.std(),\n",
   "        'cv_scores': cv_scores,\n",
   "        'cv_time': cv_time\n",
   "    }\n",
   "\n",
   "\n",
   "# Prepare data\n",
   "print(\"Preparing data...\")\n",
   "\n",
   "print(f\"Final data shapes:\")\n",
   "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
   "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
   "\n",
   "# Baseline XGBoost model with default parameters\n",
   "print(\"\\n\" + \"=\"*50)\n",
   "print(\"Evaluating Baseline XGBoost Model Performance...\")\n",
   "print(\"=\"*50)\n",
   "\n",
   "\n",
   "# Evaluate baseline model\n",
   "base_performance = evaluate_model_performance(\n",
   "    base_xgb, X_train, X_test, y_train, y_test, \"Baseline XGBoost\"\n",
   ")\n",
   "\n",
   "# Cross-validation for baseline model (using training set)\n",
   "base_cv = evaluate_cross_validation(\n",
   "    XGBRegressor(\n",
   "        random_state=Config.seed,\n",
   "        tree_method='gpu_hist',\n",
   "        n_estimators=300,  # Use fewer trees for cross-validation\n",
   "        learning_rate=0.1,\n",
   "        max_depth=6,\n",
   "        verbosity=0\n",
   "    ), \n",
   "    X_train, y_train, cv_folds=3, model_name=\"Baseline XGBoost\"  # Reduced folds for speed\n",
   ")\n",
   "\n",
   "# LightGBM model evaluation\n",
   "print(\"\\n\" + \"=\"*50)\n",
   "print(\"Evaluating LightGBM Model Performance...\")\n",
   "print(\"=\"*50)\n",
   "\n",
   "# Evaluate LightGBM model\n",
   "lgb_performance = evaluate_model_performance(\n",
   "    lgb_model, X_train, X_test, y_train, y_test, \"LightGBM\"\n",
   ")\n",
   "\n",
   "# LightGBM cross-validation\n",
   "lgb_cv = evaluate_cross_validation(\n",
   "    LGBMRegressor(\n",
   "        random_state=Config.seed,\n",
   "        n_estimators=300,\n",
   "        learning_rate=0.1,\n",
   "        max_depth=6,\n",
   "        device='gpu',\n",
   "        verbose=-1\n",
   "    ),\n",
   "    X_train, y_train, cv_folds=3, model_name=\"LightGBM\"\n",
   ")\n",
   "\n",
   "\n",
   "    \n",
   "print(\"\\n\" + \"=\"*50)\n",
   "print(\"Evaluating Tuned XGBoost Model Performance...\")\n",
   "print(\"=\"*50)\n",
   "        \n",
   "# Evaluate tuned model\n",
   "tuned_performance = evaluate_model_performance(\n",
   "            tuned_xgb, X_train, X_test, y_train, y_test, \"Tuned XGBoost\"\n",
   ")\n",
   "        \n",
   "tuned_cv = evaluate_cross_validation(\n",
   "            XGBRegressor(**tuned_cv_params, tree_method='gpu_hist', verbosity=0),\n",
   "            X_train, y_train, cv_folds=3, model_name=\"Tuned XGBoost\")\n",
   "\n",
   "erformance_summary = []\n",
   "\n",
   "# Add baseline XGBoost results\n",
   "performance_summary.append({\n",
   "    'Model': 'Baseline XGBoost',\n",
   "    'Training Time (s)': base_performance['training_time'],\n",
   "    'Train R2': base_performance['train_r2'],\n",
   "    'Test R2': base_performance['test_r2'],\n",
   "    'Overfitting Gap': base_performance['overfitting_gap'],\n",
   "    'CV Mean R2': base_cv['cv_mean_r2'],\n",
   "    'CV Std R2': base_cv['cv_std_r2'],\n",
   "    'Test RMSPE': base_performance['test_rmspe']\n",
   "})\n",
   "\n",
   "# Add LightGBM results\n",
   "performance_summary.append({\n",
   "    'Model': 'LightGBM',\n",
   "    'Training Time (s)': lgb_performance['training_time'],\n",
   "    'Train R2': lgb_performance['train_r2'],\n",
   "    'Test R2': lgb_performance['test_r2'],\n",
   "    'Overfitting Gap': lgb_performance['overfitting_gap'],\n",
   "    'CV Mean R2': lgb_cv['cv_mean_r2'],\n",
   "    'CV Std R2': lgb_cv['cv_std_r2'],\n",
   "    'Test RMSPE': lgb_performance['test_rmspe']\n",
   "})\n",
   "\n",
   "# Add tuned model results if available\n",
   "if 'tuned_performance' in locals():\n",
   "    performance_summary.append({\n",
   "        'Model': 'Tuned XGBoost',\n",
   "        'Training Time (s)': tuned_performance['training_time'],\n",
   "        'Train R2': tuned_performance['train_r2'],\n",
   "        'Test R2': tuned_performance['test_r2'],\n",
   "        'Overfitting Gap': tuned_performance['overfitting_gap'],\n",
   "        'CV Mean R2': tuned_cv['cv_mean_r2'],\n",
   "        'CV Std R2': tuned_cv['cv_std_r2'],\n",
   "        'Test RMSPE': tuned_performance['test_rmspe']\n",
   "    })\n",
   "\n",
   "# Display performance summary\n",
   "summary_df = pd.DataFrame(performance_summary)\n",
   "print(\"\\n\" + \"=\"*60)\n",
   "print(\"Model Performance Summary\")\n",
   "print(\"=\"*60)\n",
   "print(summary_df.round(5))\n",
   "\n",
   "# Visualization comparison\n",
   "try:\n",
   "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
   "    \n",
   "    models = summary_df['Model'].values\n",
   "    test_r2 = summary_df['Test R2'].values\n",
   "    cv_mean_r2 = summary_df['CV Mean R2'].values\n",
   "    \n",
   "    x = range(len(models))\n",
   "    width = 0.35\n",
   "    \n",
   "    # R2 score comparison\n",
   "    axes[0, 0].bar(x, test_r2, width, label='Test R2', alpha=0.7, color='skyblue')\n",
   "    axes[0, 0].bar([i + width for i in x], cv_mean_r2, width, label='CV Mean R2', alpha=0.7, color='lightcoral')\n",
   "    axes[0, 0].set_xlabel('Models')\n",
   "    axes[0, 0].set_ylabel('R2 Score')\n",
   "    axes[0, 0].set_title('R2 Score Comparison')\n",
   "    axes[0, 0].set_xticks([i + width/2 for i in x])\n",
   "    axes[0, 0].set_xticklabels(models, rotation=45)\n",
   "    axes[0, 0].legend()\n",
   "    axes[0, 0].grid(True, alpha=0.3)\n",
   "    \n",
   "    # Overfitting gap\n",
   "    axes[0, 1].bar(models, summary_df['Overfitting Gap'], alpha=0.7, color='orange')\n",
   "    axes[0, 1].set_xlabel('Models')\n",
   "    axes[0, 1].set_ylabel('Overfitting Gap')\n",
   "    axes[0, 1].set_title('Overfitting Gap (Train R2 - Test R2)')\n",
   "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
   "    axes[0, 1].grid(True, alpha=0.3)\n",
   "    \n",
   "    # Training time\n",
   "    axes[1, 0].bar(models, summary_df['Training Time (s)'], alpha=0.7, color='green')\n",
   "    axes[1, 0].set_xlabel('Models')\n",
   "    axes[1, 0].set_ylabel('Training Time (seconds)')\n",
   "    axes[1, 0].set_title('Training Time Comparison')\n",
   "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
   "    axes[1, 0].grid(True, alpha=0.3)\n",
   "    \n",
   "    # RMSPE comparison\n",
   "    axes[1, 1].bar(models, summary_df['Test RMSPE'], alpha=0.7, color='red')\n",
   "    axes[1, 1].set_xlabel('Models')\n",
   "    axes[1, 1].set_ylabel('RMSPE')\n",
   "    axes[1, 1].set_title('Test RMSPE Comparison')\n",
   "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
   "    axes[1, 1].grid(True, alpha=0.3)\n",
   "    \n",
   "    plt.tight_layout()\n",
   "    plt.show()\n",
   "    \n",
   "except Exception as e:\n",
   "    print(f\"Visualization creation failed: {e}\")\n",
   "\n",
   "print(\"\\n\" + \"=\"*60)\n",
   "print(\"Evaluation Completed!\")\n",
   "print(\"=\"*60)\n",
   "\n",
   "# Output key conclusions\n",
   "best_model_idx = summary_df['Test R2'].idxmax()\n",
   "best_model = summary_df.loc[best_model_idx, 'Model']\n",
   "best_test_r2 = summary_df.loc[best_model_idx, 'Test R2']\n",
   "best_rmspe = summary_df.loc[best_model_idx, 'Test RMSPE']\n",
   "\n",
   "print(f\"\\nKey Conclusions:\")\n",
   "print(f\"- Best Model: {best_model} (Test R2: {best_test_r2:.5f})\")\n",
   "print(f\"- Best Model RMSPE: {best_rmspe:.5f}\")\n",
   "print(f\"- Least Overfitting Model: {summary_df.loc[summary_df['Overfitting Gap'].idxmin(), 'Model']}\")\n",
   "print(f\"- Fastest Training Model: {summary_df.loc[summary_df['Training Time (s)'].idxmin(), 'Model']}\")\n",
   "\n",
   "# Additional detailed analysis\n",
   "print(f\"\\nDetailed Analysis:\")\n",
   "print(f\"- Cross-validation consistency:\")\n",
   "for model in summary_df['Model']:\n",
   "    model_data = summary_df[summary_df['Model'] == model].iloc[0]\n",
   "    cv_std = model_data['CV Std R2']\n",
   "    consistency = \"High\" if cv_std < 0.05 else \"Medium\" if cv_std < 0.1 else \"Low\"\n",
   "    print(f\"  {model}: CV Std = {cv_std:.5f} ({consistency} consistency)\")\n",
   "\n",
   "print(f\"- Overfitting analysis:\")\n",
   "for model in summary_df['Model']:\n",
   "    model_data = summary_df[summary_df['Model'] == model].iloc[0]\n",
   "    gap = model_data['Overfitting Gap']\n",
   "    severity = \"Low\" if gap < 0.05 else \"Medium\" if gap < 0.1 else \"High\"\n",
   "    print(f\"  {model}: Overfitting gap = {gap:.5f} ({severity} overfitting)\")"
  ]
 }
],
"metadata": {
 "kaggle": {
  "accelerator": "gpu",
  "dataSources": [
   {
    "databundleVersionId": 2344753,
    "sourceId": 27233,
    "sourceType": "competition"
   }
  ],
  "dockerImageVersionId": 30097,
  "isGpuEnabled": true,
  "isInternetEnabled": false,
  "language": "python",
  "sourceType": "notebook"
 },
 "kernelspec": {
  "display_name": "Python 3 (ipykernel)",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.10.11"
 }
},
"nbformat": 4,
"nbformat_minor": 4
}

